{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84617543, 1.7195476 , 1.85275263, ..., 1.59669981, 1.72585608,\n",
       "       1.54860615])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    e = y - tx.dot(w)\n",
    "    return e.dot(e) / (2 * N)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    \n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            losses[i, j] = compute_loss(y, tx, np.array([w0, w1]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.42448314678245, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.014 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    e = y - tx.dot(w)\n",
    "    return -tx.T.dot(e) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "    \n",
    "        w = w - gamma * grad\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.236712759165, w0=51.305745401473324, w1=9.435798704492441\n",
      "GD iter. 1/49: loss=265.3024621089666, w0=66.69746902191562, w1=12.266538315840048\n",
      "GD iter. 2/49: loss=37.878379550441835, w0=71.31498610804832, w1=13.115760199244335\n",
      "GD iter. 3/49: loss=17.41021212017456, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450487, w0=73.11581777164008, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265314, w0=73.24049073296567, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.387363601208621, w0=73.27789262136332, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.386020684743551, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261653, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638314, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.385887965652195, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543448, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613699, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.38588786890002, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835782, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829968, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829487, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829426, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829375, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829363, w0=73.29392199954958, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829448, w0=73.2939220013385, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.3858878688294, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829375, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.385887868829391, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.385887868829375, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.3858878688294, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.385887868829398, w0=73.29392200210462, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829368, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.385887868829409, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829403, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.151 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bd3027f11a433d8ba50345f6deeda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(y)\n",
    "    e = y - tx.dot(w)\n",
    "    return -tx.T.dot(e) / N\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    N = len(y)\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        indices = np.random.choice(N, batch_size, replace=False)\n",
    "        y_batch = y[indices]\n",
    "        tx_batch = tx[indices]\n",
    "\n",
    "        grad = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "        \n",
    "        w = w - gamma * grad # gamma is the lr\n",
    "        ws.append(w)\n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2077.1180495017406, w0=9.161846603309229, w1=10.232986652147462\n",
      "SGD iter. 1/49: loss=1734.9281514392965, w0=16.024265192759515, w1=26.099971389571035\n",
      "SGD iter. 2/49: loss=1274.3776938637159, w0=23.132179322037437, w1=14.815071296287162\n",
      "SGD iter. 3/49: loss=1000.7980705142554, w0=28.9390795866904, w1=15.343128543799716\n",
      "SGD iter. 4/49: loss=846.8630356484659, w0=32.57374493657746, w1=15.675498242243322\n",
      "SGD iter. 5/49: loss=695.3576145713373, w0=36.42374211302995, w1=12.749446488743981\n",
      "SGD iter. 6/49: loss=596.614928411573, w0=39.3765351321381, w1=10.005673143548957\n",
      "SGD iter. 7/49: loss=485.68289211172106, w0=42.62922858711424, w1=12.959533378901082\n",
      "SGD iter. 8/49: loss=409.22219140625515, w0=45.51367093851386, w1=9.488439715832387\n",
      "SGD iter. 9/49: loss=360.3384739548333, w0=47.59868346921682, w1=8.033623112367199\n",
      "SGD iter. 10/49: loss=290.1366838778919, w0=50.567601833445636, w1=7.733760502567122\n",
      "SGD iter. 11/49: loss=213.59480729174362, w0=53.704409542938734, w1=9.920380972763178\n",
      "SGD iter. 12/49: loss=173.4300962439185, w0=56.149630976207035, w1=8.772090745697726\n",
      "SGD iter. 13/49: loss=129.9701251173497, w0=58.34333649110354, w1=11.103061982089237\n",
      "SGD iter. 14/49: loss=114.2320234679129, w0=59.79113763313103, w1=9.559625001888303\n",
      "SGD iter. 15/49: loss=97.6573714145485, w0=60.88106380297954, w1=10.244914385676338\n",
      "SGD iter. 16/49: loss=85.21584245223211, w0=62.05536185729836, w1=9.82530755342971\n",
      "SGD iter. 17/49: loss=72.93860796001739, w0=63.44107145306004, w1=9.233917310332592\n",
      "SGD iter. 18/49: loss=51.51408773219372, w0=65.56074519937516, w1=9.950636597826161\n",
      "SGD iter. 19/49: loss=48.93597031520915, w0=65.91103596996173, w1=9.931028350833282\n",
      "SGD iter. 20/49: loss=49.19289104968839, w0=66.4895491632335, w1=8.862947698580692\n",
      "SGD iter. 21/49: loss=35.0935139023207, w0=67.84678328943666, w1=10.358185258760939\n",
      "SGD iter. 22/49: loss=33.83173958924103, w0=68.37061935123386, w1=9.922635763233647\n",
      "SGD iter. 23/49: loss=35.87692032451749, w0=67.99914978730051, w1=9.881455620264902\n",
      "SGD iter. 24/49: loss=36.58417141015881, w0=68.42591863155275, w1=9.155465648906084\n",
      "SGD iter. 25/49: loss=36.667276009693104, w0=68.56342015814866, w1=8.986926151840114\n",
      "SGD iter. 26/49: loss=40.3145806965491, w0=67.83546712739077, w1=9.000576800053897\n",
      "SGD iter. 27/49: loss=40.664699704747626, w0=68.18158653200483, w1=8.537885878644708\n",
      "SGD iter. 28/49: loss=41.93605996845513, w0=67.03712573301141, w1=9.74436176252126\n",
      "SGD iter. 29/49: loss=30.337055645920792, w0=68.3519988335301, w1=11.138829919764545\n",
      "SGD iter. 30/49: loss=28.45958709496879, w0=68.85678898781232, w1=10.938207159418841\n",
      "SGD iter. 31/49: loss=20.651370899744123, w0=70.48349865599442, w1=11.857218466598088\n",
      "SGD iter. 32/49: loss=21.350248952175836, w0=70.29329224999812, w1=11.76946588625325\n",
      "SGD iter. 33/49: loss=21.058369211074588, w0=70.3400868296268, w1=11.861126490925509\n",
      "SGD iter. 34/49: loss=21.376660507722658, w0=70.06135499242947, w1=12.241950016048085\n",
      "SGD iter. 35/49: loss=21.331665214314732, w0=70.07308086927743, w1=12.247747708198798\n",
      "SGD iter. 36/49: loss=19.93157322468081, w0=70.85649589007274, w1=11.7047970397983\n",
      "SGD iter. 37/49: loss=19.914842327136277, w0=70.88030704797666, w1=11.681832636498358\n",
      "SGD iter. 38/49: loss=22.209441372383107, w0=70.1667202344956, w1=11.51306144618422\n",
      "SGD iter. 39/49: loss=20.23548327454475, w0=70.50453096886902, w1=12.094617320878728\n",
      "SGD iter. 40/49: loss=18.408737509039568, w0=71.18361125145684, w1=12.217853561692067\n",
      "SGD iter. 41/49: loss=17.998993846091093, w0=71.47354698778506, w1=12.096800014854495\n",
      "SGD iter. 42/49: loss=18.885126166296384, w0=71.04036096210028, w1=12.094093716182929\n",
      "SGD iter. 43/49: loss=19.176689903222215, w0=70.73944156098312, w1=12.451980103732284\n",
      "SGD iter. 44/49: loss=19.264120837286324, w0=70.69330045929492, w1=12.483101413584548\n",
      "SGD iter. 45/49: loss=18.843181278513566, w0=70.84407879360951, w1=12.524277940554263\n",
      "SGD iter. 46/49: loss=18.8162429488562, w0=70.85596563464331, w1=12.52207006416081\n",
      "SGD iter. 47/49: loss=17.828888381534718, w0=71.57098366106622, w1=12.09497978989526\n",
      "SGD iter. 48/49: loss=18.056074512734032, w0=71.30582963220661, w1=12.301636878600494\n",
      "SGD iter. 49/49: loss=21.353045330930833, w0=72.6028210171025, w1=10.094938535194391\n",
      "SGD: execution time=0.052 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d41a8297e24d75b9dfc26298096b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "\n",
    "# sub data without outliers\n",
    "height_sub, weight_sub, gender_sub = load_data(sub_sample=True, add_outlier=False)\n",
    "\n",
    "# sub data with outliers\n",
    "height_ol, weight_ol, gender_ol = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x_sub, mean_x_sub, std_x_sub = standardize(height_sub)\n",
    "y_sub, tx_sub = build_model_data(x_sub, weight_sub)\n",
    "\n",
    "x_ol, mean_x_ol, std_x_ol = standardize(height_ol)\n",
    "y_ol, tx_ol = build_model_data(x_ol, weight_ol)\n",
    "\n",
    "\n",
    "#choose which one to use\n",
    "y = y_ol\n",
    "tx = tx_ol\n",
    "\n",
    "height = height_ol\n",
    "weight = weight_ol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358524, w0=51.84746409844842, w1=7.7244264061924195\n",
      "GD iter. 1/49: loss=318.28212470159644, w0=67.40170332798297, w1=10.041754328050114\n",
      "GD iter. 2/49: loss=88.64235561651282, w0=72.06797509684336, w1=10.736952704607411\n",
      "GD iter. 3/49: loss=67.97477639885523, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631798\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.05160722578589, w1=11.032481534481914\n",
      "GD iter. 7/49: loss=65.93086421248087, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249234, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889339, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003895\n",
      "GD iter. 11/49: loss=65.93073011140233, w0=74.06776649225755, w1=11.034889001593541\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267464, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608874, w1=11.034894818487496\n",
      "GD iter. 16/49: loss=65.93073010260343, w0=74.06780575927507, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260339, w0=74.06780582623098, w1=11.034894861713955\n",
      "GD iter. 18/49: loss=65.93073010260336, w0=74.06780584631775, w1=11.034894864706557\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260339, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260336, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260336, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.06780585492008, w1=11.034894865988164\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.03489486598882\n",
      "GD iter. 26/49: loss=65.93073010260339, w0=74.06780585492581, w1=11.034894865989015\n",
      "GD iter. 27/49: loss=65.93073010260336, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.0678058549263, w1=11.034894865989099\n",
      "GD iter. 29/49: loss=65.93073010260339, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260336, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f387dfe150477fbc609310a7ee09c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    e = y - tx.dot(w)\n",
    "    return -tx.T.dot(np.sign(e)) / N  # np.sign(e) is the subgrad of the MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "   \n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        \n",
    "        w = w - gamma * subgrad    \n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=2869.8351145358524, w0=0.7, w1=6.109524327590712e-16\n",
      "SubGD iter. 1/499: loss=2818.2326504374055, w0=1.4, w1=1.2219048655181425e-15\n",
      "SubGD iter. 2/499: loss=2767.120186338956, w0=2.0999999999999996, w1=1.832857298277214e-15\n",
      "SubGD iter. 3/499: loss=2716.497722240507, w0=2.8, w1=2.443809731036285e-15\n",
      "SubGD iter. 4/499: loss=2666.365258142059, w0=3.5, w1=3.054762163795356e-15\n",
      "SubGD iter. 5/499: loss=2616.7227940436114, w0=4.2, w1=3.665714596554428e-15\n",
      "SubGD iter. 6/499: loss=2567.570329945162, w0=4.9, w1=4.276667029313499e-15\n",
      "SubGD iter. 7/499: loss=2518.907865846713, w0=5.6000000000000005, w1=4.887619462072571e-15\n",
      "SubGD iter. 8/499: loss=2470.7354017482644, w0=6.300000000000001, w1=5.498571894831642e-15\n",
      "SubGD iter. 9/499: loss=2423.052937649816, w0=7.000000000000001, w1=6.109524327590714e-15\n",
      "SubGD iter. 10/499: loss=2375.8604735513686, w0=7.700000000000001, w1=6.720476760349785e-15\n",
      "SubGD iter. 11/499: loss=2329.15800945292, w0=8.4, w1=7.331429193108857e-15\n",
      "SubGD iter. 12/499: loss=2282.9455453544715, w0=9.1, w1=7.942381625867928e-15\n",
      "SubGD iter. 13/499: loss=2237.2230812560233, w0=9.799999999999999, w1=8.553334058627e-15\n",
      "SubGD iter. 14/499: loss=2191.990617157574, w0=10.499999999999998, w1=9.164286491386072e-15\n",
      "SubGD iter. 15/499: loss=2147.248153059126, w0=11.199999999999998, w1=9.775238924145143e-15\n",
      "SubGD iter. 16/499: loss=2102.9956889606774, w0=11.899999999999997, w1=1.0386191356904215e-14\n",
      "SubGD iter. 17/499: loss=2059.2332248622283, w0=12.599999999999996, w1=1.0997143789663286e-14\n",
      "SubGD iter. 18/499: loss=2015.9607607637806, w0=13.299999999999995, w1=1.1608096222422358e-14\n",
      "SubGD iter. 19/499: loss=1973.178296665333, w0=13.999999999999995, w1=1.2219048655181429e-14\n",
      "SubGD iter. 20/499: loss=1930.8858325668837, w0=14.699999999999994, w1=1.28300010879405e-14\n",
      "SubGD iter. 21/499: loss=1889.0833684684346, w0=15.399999999999993, w1=1.3440953520699572e-14\n",
      "SubGD iter. 22/499: loss=1847.7709043699867, w0=16.099999999999994, w1=1.4051905953458644e-14\n",
      "SubGD iter. 23/499: loss=1806.9484402715386, w0=16.799999999999994, w1=1.4662858386217714e-14\n",
      "SubGD iter. 24/499: loss=1766.615976173091, w0=17.499999999999993, w1=1.5273810818976784e-14\n",
      "SubGD iter. 25/499: loss=1726.7735120746408, w0=18.199999999999992, w1=1.5884763251735854e-14\n",
      "SubGD iter. 26/499: loss=1687.4210479761932, w0=18.89999999999999, w1=1.6495715684494924e-14\n",
      "SubGD iter. 27/499: loss=1648.5585838777456, w0=19.59999999999999, w1=1.7106668117253994e-14\n",
      "SubGD iter. 28/499: loss=1610.1861197792962, w0=20.29999999999999, w1=1.7717620550013064e-14\n",
      "SubGD iter. 29/499: loss=1572.3036556808481, w0=20.99999999999999, w1=1.8328572982772134e-14\n",
      "SubGD iter. 30/499: loss=1534.9111915823992, w0=21.69999999999999, w1=1.8939525415531204e-14\n",
      "SubGD iter. 31/499: loss=1498.0087274839505, w0=22.399999999999988, w1=1.9550477848290273e-14\n",
      "SubGD iter. 32/499: loss=1461.596263385502, w0=23.099999999999987, w1=2.0161430281049343e-14\n",
      "SubGD iter. 33/499: loss=1425.6737992870537, w0=23.799999999999986, w1=2.0772382713808413e-14\n",
      "SubGD iter. 34/499: loss=1390.2413351886055, w0=24.499999999999986, w1=2.1383335146567483e-14\n",
      "SubGD iter. 35/499: loss=1355.298871090157, w0=25.199999999999985, w1=2.1994287579326553e-14\n",
      "SubGD iter. 36/499: loss=1320.8464069917086, w0=25.899999999999984, w1=2.2605240012085623e-14\n",
      "SubGD iter. 37/499: loss=1286.8839428932602, w0=26.599999999999984, w1=2.3216192444844693e-14\n",
      "SubGD iter. 38/499: loss=1253.4114787948117, w0=27.299999999999983, w1=2.3827144877603763e-14\n",
      "SubGD iter. 39/499: loss=1220.4290146963638, w0=27.999999999999982, w1=2.4438097310362833e-14\n",
      "SubGD iter. 40/499: loss=1187.936550597915, w0=28.69999999999998, w1=2.5049049743121903e-14\n",
      "SubGD iter. 41/499: loss=1155.9340864994665, w0=29.39999999999998, w1=2.5660002175880973e-14\n",
      "SubGD iter. 42/499: loss=1124.4216224010179, w0=30.09999999999998, w1=2.6270954608640043e-14\n",
      "SubGD iter. 43/499: loss=1093.39915830257, w0=30.79999999999998, w1=2.6881907041399113e-14\n",
      "SubGD iter. 44/499: loss=1062.866694204121, w0=31.49999999999998, w1=2.7492859474158183e-14\n",
      "SubGD iter. 45/499: loss=1032.8242301056725, w0=32.19999999999998, w1=2.8103811906917253e-14\n",
      "SubGD iter. 46/499: loss=1003.2717660072241, w0=32.899999999999984, w1=2.871476433967632e-14\n",
      "SubGD iter. 47/499: loss=974.2093019087754, w0=33.59999999999999, w1=2.9325716772435396e-14\n",
      "SubGD iter. 48/499: loss=945.6368378103266, w0=34.29999999999999, w1=2.993666920519447e-14\n",
      "SubGD iter. 49/499: loss=917.5543737118778, w0=34.99999999999999, w1=3.054762163795354e-14\n",
      "SubGD iter. 50/499: loss=889.9619096134298, w0=35.699999999999996, w1=3.1158574070712615e-14\n",
      "SubGD iter. 51/499: loss=862.8594455149807, w0=36.4, w1=3.176952650347169e-14\n",
      "SubGD iter. 52/499: loss=836.2469814165324, w0=37.1, w1=3.238047893623076e-14\n",
      "SubGD iter. 53/499: loss=810.1245173180839, w0=37.800000000000004, w1=3.2991431368989835e-14\n",
      "SubGD iter. 54/499: loss=784.4920532196355, w0=38.50000000000001, w1=3.360238380174891e-14\n",
      "SubGD iter. 55/499: loss=759.3495891211865, w0=39.20000000000001, w1=3.421333623450798e-14\n",
      "SubGD iter. 56/499: loss=734.6971250227382, w0=39.90000000000001, w1=3.4824288667267054e-14\n",
      "SubGD iter. 57/499: loss=710.5346609242895, w0=40.600000000000016, w1=3.543524110002613e-14\n",
      "SubGD iter. 58/499: loss=686.8621968258414, w0=41.30000000000002, w1=3.60461935327852e-14\n",
      "SubGD iter. 59/499: loss=663.6797327273924, w0=42.00000000000002, w1=3.6657145965544273e-14\n",
      "SubGD iter. 60/499: loss=640.9872686289438, w0=42.700000000000024, w1=3.7268098398303347e-14\n",
      "SubGD iter. 61/499: loss=618.7848045304954, w0=43.40000000000003, w1=3.787905083106242e-14\n",
      "SubGD iter. 62/499: loss=597.0723404320468, w0=44.10000000000003, w1=3.849000326382149e-14\n",
      "SubGD iter. 63/499: loss=575.8498763335982, w0=44.80000000000003, w1=3.9100955696580566e-14\n",
      "SubGD iter. 64/499: loss=555.1174122351497, w0=45.500000000000036, w1=3.971190812933964e-14\n",
      "SubGD iter. 65/499: loss=534.8749481367012, w0=46.20000000000004, w1=4.032286056209871e-14\n",
      "SubGD iter. 66/499: loss=515.1224840382527, w0=46.90000000000004, w1=4.0933812994857785e-14\n",
      "SubGD iter. 67/499: loss=495.86001993980426, w0=47.59306930693074, w1=0.011147845678271063\n",
      "SubGD iter. 68/499: loss=477.14806692939743, w0=48.279207920792125, w1=0.03308574108989941\n",
      "SubGD iter. 69/499: loss=458.97652381717785, w0=48.96534653465351, w1=0.05502363650152776\n",
      "SubGD iter. 70/499: loss=441.2762481736448, w0=49.63069306930698, w1=0.10538326388307814\n",
      "SubGD iter. 71/499: loss=424.24408268143014, w0=50.28910891089114, w1=0.16746568532793435\n",
      "SubGD iter. 72/499: loss=407.6944527790814, w0=50.947524752475296, w1=0.22954810677279056\n",
      "SubGD iter. 73/499: loss=391.58218852423494, w0=51.59207920792084, w1=0.31242512932747524\n",
      "SubGD iter. 74/499: loss=375.99555288487295, w0=52.22277227722777, w1=0.4119501328839991\n",
      "SubGD iter. 75/499: loss=360.95695350929606, w0=52.84653465346539, w1=0.5208167847923756\n",
      "SubGD iter. 76/499: loss=346.3748247543329, w0=53.4564356435644, w1=0.6457900912635992\n",
      "SubGD iter. 77/499: loss=332.3117701076255, w0=54.0594059405941, w1=0.7796904498577214\n",
      "SubGD iter. 78/499: loss=318.68337247684957, w0=54.655445544554496, w1=0.9197570104995693\n",
      "SubGD iter. 79/499: loss=305.5086034302328, w0=55.24455445544559, w1=1.0670920297849913\n",
      "SubGD iter. 80/499: loss=292.76667341735055, w0=55.819801980198065, w1=1.2261255948210765\n",
      "SubGD iter. 81/499: loss=280.53153011615814, w0=56.36732673267331, w1=1.410709342622213\n",
      "SubGD iter. 82/499: loss=268.89668417535404, w0=56.900990099009945, w1=1.605853732220269\n",
      "SubGD iter. 83/499: loss=257.73392005254595, w0=57.42772277227727, w1=1.808762802293962\n",
      "SubGD iter. 84/499: loss=246.9376690297076, w0=57.933663366336674, w1=2.0285064197514697\n",
      "SubGD iter. 85/499: loss=236.64352344592243, w0=58.43267326732677, w1=2.2494370848672776\n",
      "SubGD iter. 86/499: loss=226.75154983045, w0=58.91089108910895, w1=2.4837982986028337\n",
      "SubGD iter. 87/499: loss=217.35738896411308, w0=59.382178217821824, w1=2.7260245553531504\n",
      "SubGD iter. 88/499: loss=208.28322256993155, w0=59.83960396039608, w1=2.978742333469136\n",
      "SubGD iter. 89/499: loss=199.60239149197503, w0=60.262376237623805, w1=3.251528669355438\n",
      "SubGD iter. 90/499: loss=191.5160682372007, w0=60.67821782178222, w1=3.5270865794242794\n",
      "SubGD iter. 91/499: loss=183.75485658516766, w0=61.087128712871326, w1=3.806459183951815\n",
      "SubGD iter. 92/499: loss=176.30486084041354, w0=61.49603960396043, w1=4.085831788479351\n",
      "SubGD iter. 93/499: loss=169.10012226467117, w0=61.891089108910926, w1=4.373839384328607\n",
      "SubGD iter. 94/499: loss=162.2517755238296, w0=62.27920792079211, w1=4.666037469532047\n",
      "SubGD iter. 95/499: loss=155.69742299714352, w0=62.65346534653469, w1=4.959829093241769\n",
      "SubGD iter. 96/499: loss=149.5275267949621, w0=63.02079207920796, w1=5.25705719205664\n",
      "SubGD iter. 97/499: loss=143.64069087621618, w0=63.38118811881192, w1=5.560434316352406\n",
      "SubGD iter. 98/499: loss=138.01748857628564, w0=63.74158415841588, w1=5.863811440648173\n",
      "SubGD iter. 99/499: loss=132.61620926126324, w0=64.08811881188123, w1=6.172402175278548\n",
      "SubGD iter. 100/499: loss=127.5497244247717, w0=64.42772277227726, w1=6.486369310516498\n",
      "SubGD iter. 101/499: loss=122.74087338718577, w0=64.7673267326733, w1=6.800336445754448\n",
      "SubGD iter. 102/499: loss=118.14592856152613, w0=65.10693069306933, w1=7.114303580992399\n",
      "SubGD iter. 103/499: loss=113.76488994779264, w0=65.44653465346536, w1=7.428270716230349\n",
      "SubGD iter. 104/499: loss=109.59775754598536, w0=65.76534653465349, w1=7.747893210218626\n",
      "SubGD iter. 105/499: loss=105.7983354275153, w0=66.070297029703, w1=8.073669686866905\n",
      "SubGD iter. 106/499: loss=102.29523108809985, w0=66.37524752475251, w1=8.399446163515185\n",
      "SubGD iter. 107/499: loss=98.99125186585275, w0=66.6663366336634, w1=8.73297028041739\n",
      "SubGD iter. 108/499: loss=95.97103181808463, w0=66.9574257425743, w1=9.066494397319596\n",
      "SubGD iter. 109/499: loss=93.14678297619841, w0=67.23465346534658, w1=9.39863031947029\n",
      "SubGD iter. 110/499: loss=90.61539672531053, w0=67.51188118811886, w1=9.730766241620982\n",
      "SubGD iter. 111/499: loss=88.27117995547904, w0=67.78910891089114, w1=10.062902163771675\n",
      "SubGD iter. 112/499: loss=86.11413266670401, w0=68.06633663366343, w1=10.363999289979422\n",
      "SubGD iter. 113/499: loss=84.16459694644126, w0=68.32970297029709, w1=10.660466909273612\n",
      "SubGD iter. 114/499: loss=82.46374060728385, w0=68.59306930693076, w1=10.943174379960814\n",
      "SubGD iter. 115/499: loss=80.92130656136146, w0=68.85643564356442, w1=11.225881850648015\n",
      "SubGD iter. 116/499: loss=79.52815785669323, w0=69.11287128712878, w1=11.504395843582206\n",
      "SubGD iter. 117/499: loss=78.31663397216153, w0=69.35544554455453, w1=11.78820189306775\n",
      "SubGD iter. 118/499: loss=77.31763568851031, w0=69.58415841584166, w1=12.060911465190971\n",
      "SubGD iter. 119/499: loss=76.5086323125277, w0=69.80594059405948, w1=12.324245668386048\n",
      "SubGD iter. 120/499: loss=75.84369059931619, w0=70.0277227722773, w1=12.587579871581125\n",
      "SubGD iter. 121/499: loss=75.2972811232521, w0=70.25643564356443, w1=12.824765405096484\n",
      "SubGD iter. 122/499: loss=74.7958198200142, w0=70.47821782178225, w1=13.065616959310148\n",
      "SubGD iter. 123/499: loss=74.43521733660019, w0=70.69306930693077, w1=13.302953389983912\n",
      "SubGD iter. 124/499: loss=74.19719822092476, w0=70.89405940594067, w1=13.525403099312918\n",
      "SubGD iter. 125/499: loss=74.06837899395488, w0=71.08811881188126, w1=13.742945617944212\n",
      "SubGD iter. 126/499: loss=74.03676697743113, w0=71.27524752475254, w1=13.953548196006844\n",
      "SubGD iter. 127/499: loss=74.08918974672679, w0=71.46237623762383, w1=14.164150774069476\n",
      "SubGD iter. 128/499: loss=74.22098311708997, w0=71.62178217821788, w1=14.349779559473173\n",
      "SubGD iter. 129/499: loss=74.41647628166011, w0=71.75346534653471, w1=14.51689010761231\n",
      "SubGD iter. 130/499: loss=74.67096152833797, w0=71.87128712871292, w1=14.670791185324186\n",
      "SubGD iter. 131/499: loss=74.95294838238374, w0=71.95445544554461, w1=14.780276456654521\n",
      "SubGD iter. 132/499: loss=75.17779670886809, w0=72.0376237623763, w1=14.889761727984856\n",
      "SubGD iter. 133/499: loss=75.42154902891535, w0=72.10693069306937, w1=14.985916181776727\n",
      "SubGD iter. 134/499: loss=75.6585305217013, w0=72.17623762376245, w1=15.082070635568597\n",
      "SubGD iter. 135/499: loss=75.90956114411335, w0=72.24554455445552, w1=15.178225089360467\n",
      "SubGD iter. 136/499: loss=76.17464089615152, w0=72.30099009900998, w1=15.25972348971591\n",
      "SubGD iter. 137/499: loss=76.41613751021124, w0=72.34950495049513, w1=15.335091856448138\n",
      "SubGD iter. 138/499: loss=76.65285618006445, w0=72.39801980198028, w1=15.410460223180365\n",
      "SubGD iter. 139/499: loss=76.89760893143615, w0=72.43267326732682, w1=15.469961786755725\n",
      "SubGD iter. 140/499: loss=77.10246868795753, w0=72.46039603960405, w1=15.51864528583281\n",
      "SubGD iter. 141/499: loss=77.27462217352495, w0=72.48811881188128, w1=15.561592159086487\n",
      "SubGD iter. 142/499: loss=77.42392987125324, w0=72.5019801980199, w1=15.597828332032526\n",
      "SubGD iter. 143/499: loss=77.5668160042862, w0=72.52277227722782, w1=15.624722856626713\n",
      "SubGD iter. 144/499: loss=77.65755497253161, w0=72.55049504950505, w1=15.642690329098\n",
      "SubGD iter. 145/499: loss=77.697735657651, w0=72.56435643564366, w1=15.664356578291091\n",
      "SubGD iter. 146/499: loss=77.77686805360916, w0=72.58514851485158, w1=15.677095775361284\n",
      "SubGD iter. 147/499: loss=77.80488113813016, w0=72.6059405940595, w1=15.689834972431477\n",
      "SubGD iter. 148/499: loss=77.83348882035091, w0=72.62673267326743, w1=15.70257416950167\n",
      "SubGD iter. 149/499: loss=77.86269110027148, w0=72.64059405940604, w1=15.72424041869476\n",
      "SubGD iter. 150/499: loss=77.9441777135797, w0=72.66138613861396, w1=15.736979615764954\n",
      "SubGD iter. 151/499: loss=77.97453880885682, w0=72.66831683168327, w1=15.74811029423128\n",
      "SubGD iter. 152/499: loss=78.01721470220238, w0=72.67524752475258, w1=15.759240972697606\n",
      "SubGD iter. 153/499: loss=78.06006252205748, w0=72.68217821782189, w1=15.770371651163932\n",
      "SubGD iter. 154/499: loss=78.10308226842213, w0=72.68217821782189, w1=15.774323911906686\n",
      "SubGD iter. 155/499: loss=78.12180591760087, w0=72.68217821782189, w1=15.77827617264944\n",
      "SubGD iter. 156/499: loss=78.14054518714461, w0=72.68217821782189, w1=15.782228433392193\n",
      "SubGD iter. 157/499: loss=78.15930007705333, w0=72.68217821782189, w1=15.786180694134947\n",
      "SubGD iter. 158/499: loss=78.17807058732701, w0=72.68217821782189, w1=15.7901329548777\n",
      "SubGD iter. 159/499: loss=78.19685671796569, w0=72.68217821782189, w1=15.794085215620454\n",
      "SubGD iter. 160/499: loss=78.21565846896934, w0=72.68217821782189, w1=15.798037476363207\n",
      "SubGD iter. 161/499: loss=78.23447584033798, w0=72.68217821782189, w1=15.801989737105961\n",
      "SubGD iter. 162/499: loss=78.25330883207157, w0=72.68217821782189, w1=15.805941997848715\n",
      "SubGD iter. 163/499: loss=78.27215744417016, w0=72.68217821782189, w1=15.809894258591468\n",
      "SubGD iter. 164/499: loss=78.29102167663373, w0=72.68217821782189, w1=15.813846519334222\n",
      "SubGD iter. 165/499: loss=78.30990152946228, w0=72.68217821782189, w1=15.817798780076975\n",
      "SubGD iter. 166/499: loss=78.32879700265579, w0=72.68217821782189, w1=15.821751040819729\n",
      "SubGD iter. 167/499: loss=78.34770809621429, w0=72.68217821782189, w1=15.825703301562482\n",
      "SubGD iter. 168/499: loss=78.36663481013778, w0=72.68217821782189, w1=15.829655562305236\n",
      "SubGD iter. 169/499: loss=78.38557714442622, w0=72.68217821782189, w1=15.83360782304799\n",
      "SubGD iter. 170/499: loss=78.40453509907967, w0=72.68217821782189, w1=15.837560083790743\n",
      "SubGD iter. 171/499: loss=78.42350867409809, w0=72.68217821782189, w1=15.841512344533497\n",
      "SubGD iter. 172/499: loss=78.44249786948147, w0=72.68217821782189, w1=15.84546460527625\n",
      "SubGD iter. 173/499: loss=78.46150268522986, w0=72.68217821782189, w1=15.849416866019004\n",
      "SubGD iter. 174/499: loss=78.48052312134321, w0=72.68217821782189, w1=15.853369126761757\n",
      "SubGD iter. 175/499: loss=78.49955917782154, w0=72.68217821782189, w1=15.857321387504511\n",
      "SubGD iter. 176/499: loss=78.51861085466484, w0=72.68217821782189, w1=15.861273648247264\n",
      "SubGD iter. 177/499: loss=78.53767815187315, w0=72.68217821782189, w1=15.865225908990018\n",
      "SubGD iter. 178/499: loss=78.55676106944641, w0=72.68217821782189, w1=15.869178169732772\n",
      "SubGD iter. 179/499: loss=78.57585960738464, w0=72.68217821782189, w1=15.873130430475525\n",
      "SubGD iter. 180/499: loss=78.59497376568787, w0=72.68217821782189, w1=15.877082691218279\n",
      "SubGD iter. 181/499: loss=78.61410354435607, w0=72.68217821782189, w1=15.881034951961032\n",
      "SubGD iter. 182/499: loss=78.63324894338926, w0=72.68217821782189, w1=15.884987212703786\n",
      "SubGD iter. 183/499: loss=78.65240996278743, w0=72.68217821782189, w1=15.88893947344654\n",
      "SubGD iter. 184/499: loss=78.67158660255056, w0=72.68217821782189, w1=15.892891734189293\n",
      "SubGD iter. 185/499: loss=78.69077886267867, w0=72.68217821782189, w1=15.896843994932047\n",
      "SubGD iter. 186/499: loss=78.70998674317177, w0=72.68217821782189, w1=15.9007962556748\n",
      "SubGD iter. 187/499: loss=78.72921024402986, w0=72.68217821782189, w1=15.904748516417554\n",
      "SubGD iter. 188/499: loss=78.7484493652529, w0=72.68217821782189, w1=15.908700777160307\n",
      "SubGD iter. 189/499: loss=78.76770410684094, w0=72.68217821782189, w1=15.91265303790306\n",
      "SubGD iter. 190/499: loss=78.78697446879396, w0=72.67524752475258, w1=15.910526938117323\n",
      "SubGD iter. 191/499: loss=78.78623350545425, w0=72.67524752475258, w1=15.914479198860077\n",
      "SubGD iter. 192/499: loss=78.80551108487151, w0=72.67524752475258, w1=15.91843145960283\n",
      "SubGD iter. 193/499: loss=78.82480428465377, w0=72.66831683168327, w1=15.916305359817093\n",
      "SubGD iter. 194/499: loss=78.82409907031933, w0=72.66831683168327, w1=15.920257620559847\n",
      "SubGD iter. 195/499: loss=78.84339948756585, w0=72.66831683168327, w1=15.9242098813026\n",
      "SubGD iter. 196/499: loss=78.86271552517734, w0=72.66831683168327, w1=15.928162142045354\n",
      "SubGD iter. 197/499: loss=78.88204718315382, w0=72.66138613861396, w1=15.926036042259616\n",
      "SubGD iter. 198/499: loss=78.88136931492397, w0=72.66138613861396, w1=15.92998830300237\n",
      "SubGD iter. 199/499: loss=78.90070819036468, w0=72.66138613861396, w1=15.933940563745123\n",
      "SubGD iter. 200/499: loss=78.9200626861704, w0=72.65445544554466, w1=15.931814463959386\n",
      "SubGD iter. 201/499: loss=78.91942056694582, w0=72.65445544554466, w1=15.93576672470214\n",
      "SubGD iter. 202/499: loss=78.93878228021579, w0=72.65445544554466, w1=15.939718985444893\n",
      "SubGD iter. 203/499: loss=78.95815961385074, w0=72.65445544554466, w1=15.943671246187646\n",
      "SubGD iter. 204/499: loss=78.97755256785065, w0=72.64752475247535, w1=15.941545146401909\n",
      "SubGD iter. 205/499: loss=78.97693779473065, w0=72.64752475247535, w1=15.945497407144662\n",
      "SubGD iter. 206/499: loss=78.99633796619483, w0=72.64752475247535, w1=15.949449667887416\n",
      "SubGD iter. 207/499: loss=79.01575375802399, w0=72.64059405940604, w1=15.947323568101679\n",
      "SubGD iter. 208/499: loss=79.01517473390926, w0=72.64059405940604, w1=15.951275828844432\n",
      "SubGD iter. 209/499: loss=79.0345977432027, w0=72.64059405940604, w1=15.955228089587186\n",
      "SubGD iter. 210/499: loss=79.0540363728611, w0=72.64059405940604, w1=15.95918035032994\n",
      "SubGD iter. 211/499: loss=79.07349062288448, w0=72.63366336633673, w1=15.957054250544202\n",
      "SubGD iter. 212/499: loss=79.07293894487434, w0=72.63366336633673, w1=15.961006511286955\n",
      "SubGD iter. 213/499: loss=79.09240041236197, w0=72.63366336633673, w1=15.964958772029709\n",
      "SubGD iter. 214/499: loss=79.11187750021459, w0=72.62673267326743, w1=15.962832672243971\n",
      "SubGD iter. 215/499: loss=79.11136157120971, w0=72.63366336633673, w1=15.967301372051375\n",
      "SubGD iter. 216/499: loss=79.12342941191513, w0=72.62673267326743, w1=15.965175272265638\n",
      "SubGD iter. 217/499: loss=79.12290850230885, w0=72.63366336633673, w1=15.969643972073042\n",
      "SubGD iter. 218/499: loss=79.13498681139052, w0=72.62673267326743, w1=15.967517872287305\n",
      "SubGD iter. 219/499: loss=79.13446092118285, w0=72.63366336633673, w1=15.971986572094709\n",
      "SubGD iter. 220/499: loss=79.14654969864078, w0=72.62673267326743, w1=15.969860472308971\n",
      "SubGD iter. 221/499: loss=79.1460188278317, w0=72.63366336633673, w1=15.974329172116375\n",
      "SubGD iter. 222/499: loss=79.1581180736659, w0=72.62673267326743, w1=15.972203072330638\n",
      "SubGD iter. 223/499: loss=79.15758222225543, w0=72.62673267326743, w1=15.970593411609551\n",
      "SubGD iter. 224/499: loss=79.14963612667158, w0=72.63366336633673, w1=15.975062111416955\n",
      "SubGD iter. 225/499: loss=79.16173864779152, w0=72.62673267326743, w1=15.972936011631218\n",
      "SubGD iter. 226/499: loss=79.16120123807893, w0=72.62673267326743, w1=15.97132635091013\n",
      "SubGD iter. 227/499: loss=79.15325396271149, w0=72.63366336633673, w1=15.975795050717535\n",
      "SubGD iter. 228/499: loss=79.16535975911714, w0=72.62673267326743, w1=15.973668950931797\n",
      "SubGD iter. 229/499: loss=79.16482079110246, w0=72.62673267326743, w1=15.97205929021071\n",
      "SubGD iter. 230/499: loss=79.15687233595143, w0=72.62673267326743, w1=15.970449629489623\n",
      "SubGD iter. 231/499: loss=79.14892647180802, w0=72.63366336633673, w1=15.974918329297028\n",
      "SubGD iter. 232/499: loss=79.16102835040883, w0=72.62673267326743, w1=15.97279222951129\n",
      "SubGD iter. 233/499: loss=79.16049124639136, w0=72.62673267326743, w1=15.971182568790203\n",
      "SubGD iter. 234/499: loss=79.15254420246437, w0=72.63366336633673, w1=15.975651268597607\n",
      "SubGD iter. 235/499: loss=79.16464935635088, w0=72.62673267326743, w1=15.97352516881187\n",
      "SubGD iter. 236/499: loss=79.16411069403134, w0=72.62673267326743, w1=15.971915508090783\n",
      "SubGD iter. 237/499: loss=79.15616247032072, w0=72.63366336633673, w1=15.976384207898187\n",
      "SubGD iter. 238/499: loss=79.16827089949295, w0=72.62673267326743, w1=15.97425810811245\n",
      "SubGD iter. 239/499: loss=79.16773067887131, w0=72.62673267326743, w1=15.972648447391363\n",
      "SubGD iter. 240/499: loss=79.1597812753771, w0=72.62673267326743, w1=15.971038786670276\n",
      "SubGD iter. 241/499: loss=79.15183446289053, w0=72.63366336633673, w1=15.97550748647768\n",
      "SubGD iter. 242/499: loss=79.16393897425792, w0=72.62673267326743, w1=15.973381386691942\n",
      "SubGD iter. 243/499: loss=79.16340061763351, w0=72.62673267326743, w1=15.971771725970855\n",
      "SubGD iter. 244/499: loss=79.15545262536332, w0=72.63366336633673, w1=15.97624042577826\n",
      "SubGD iter. 245/499: loss=79.16756041201641, w0=72.62673267326743, w1=15.974114325992522\n",
      "SubGD iter. 246/499: loss=79.16702049708991, w0=72.62673267326743, w1=15.972504665271435\n",
      "SubGD iter. 247/499: loss=79.15907132503614, w0=72.62673267326743, w1=15.970895004550348\n",
      "SubGD iter. 248/499: loss=79.15112474399, w0=72.63366336633673, w1=15.975363704357752\n",
      "SubGD iter. 249/499: loss=79.16322861283825, w0=72.62673267326743, w1=15.973237604572015\n",
      "SubGD iter. 250/499: loss=79.16269056190897, w0=72.62673267326743, w1=15.971627943850928\n",
      "SubGD iter. 251/499: loss=79.15474280107922, w0=72.63366336633673, w1=15.976096643658332\n",
      "SubGD iter. 252/499: loss=79.16684994521319, w0=72.62673267326743, w1=15.973970543872595\n",
      "SubGD iter. 253/499: loss=79.16631033598182, w0=72.62673267326743, w1=15.972360883151508\n",
      "SubGD iter. 254/499: loss=79.15836139536847, w0=72.62673267326743, w1=15.97075122243042\n",
      "SubGD iter. 255/499: loss=79.15041504576276, w0=72.63366336633673, w1=15.975219922237825\n",
      "SubGD iter. 256/499: loss=79.16251827209187, w0=72.62673267326743, w1=15.973093822452087\n",
      "SubGD iter. 257/499: loss=79.16198052685773, w0=72.62673267326743, w1=15.971484161731\n",
      "SubGD iter. 258/499: loss=79.15403299746842, w0=72.63366336633673, w1=15.975952861538405\n",
      "SubGD iter. 259/499: loss=79.16613949908324, w0=72.62673267326743, w1=15.973826761752667\n",
      "SubGD iter. 260/499: loss=79.16560019554703, w0=72.62673267326743, w1=15.97221710103158\n",
      "SubGD iter. 261/499: loss=79.1576514863741, w0=72.62673267326743, w1=15.970607440310493\n",
      "SubGD iter. 262/499: loss=79.14970536820883, w0=72.63366336633673, w1=15.975076140117897\n",
      "SubGD iter. 263/499: loss=79.1618079520188, w0=72.62673267326743, w1=15.97295004033216\n",
      "SubGD iter. 264/499: loss=79.1612705124798, w0=72.62673267326743, w1=15.971340379611073\n",
      "SubGD iter. 265/499: loss=79.15332321453093, w0=72.63366336633673, w1=15.975809079418477\n",
      "SubGD iter. 266/499: loss=79.1654290736266, w0=72.62673267326743, w1=15.97368297963274\n",
      "SubGD iter. 267/499: loss=79.16489007578554, w0=72.62673267326743, w1=15.972073318911653\n",
      "SubGD iter. 268/499: loss=79.15694159805304, w0=72.62673267326743, w1=15.970463658190566\n",
      "SubGD iter. 269/499: loss=79.14899571132818, w0=72.63366336633673, w1=15.97493235799797\n",
      "SubGD iter. 270/499: loss=79.16109765261903, w0=72.62673267326743, w1=15.972806258212232\n",
      "SubGD iter. 271/499: loss=79.16056051877517, w0=72.62673267326743, w1=15.971196597491145\n",
      "SubGD iter. 272/499: loss=79.15261345226672, w0=72.63366336633673, w1=15.97566529729855\n",
      "SubGD iter. 273/499: loss=79.16471866884326, w0=72.62673267326743, w1=15.973539197512812\n",
      "SubGD iter. 274/499: loss=79.16417997669733, w0=72.62673267326743, w1=15.971929536791725\n",
      "SubGD iter. 275/499: loss=79.15623173040527, w0=72.63366336633673, w1=15.97639823659913\n",
      "SubGD iter. 276/499: loss=79.16834022226753, w0=72.62673267326743, w1=15.974272136813392\n",
      "SubGD iter. 277/499: loss=79.16779997181949, w0=72.62673267326743, w1=15.972662476092305\n",
      "SubGD iter. 278/499: loss=79.15985054574384, w0=72.62673267326743, w1=15.971052815371218\n",
      "SubGD iter. 279/499: loss=79.15190371067581, w0=72.63366336633673, w1=15.975521515178622\n",
      "SubGD iter. 280/499: loss=79.16400828473324, w0=72.62673267326743, w1=15.973395415392885\n",
      "SubGD iter. 281/499: loss=79.16346989828241, w0=72.62673267326743, w1=15.971785754671798\n",
      "SubGD iter. 282/499: loss=79.1555218834308, w0=72.63366336633673, w1=15.976254454479202\n",
      "SubGD iter. 283/499: loss=79.16762973277392, w0=72.62673267326743, w1=15.974128354693464\n",
      "SubGD iter. 284/499: loss=79.16708978802103, w0=72.62673267326743, w1=15.972518693972377\n",
      "SubGD iter. 285/499: loss=79.15914059338579, w0=72.62673267326743, w1=15.97090903325129\n",
      "SubGD iter. 286/499: loss=79.1511939897582, w0=72.63366336633673, w1=15.975377733058695\n",
      "SubGD iter. 287/499: loss=79.1632979212965, w0=72.62673267326743, w1=15.973251633272957\n",
      "SubGD iter. 288/499: loss=79.1627598405408, w0=72.62673267326743, w1=15.97164197255187\n",
      "SubGD iter. 289/499: loss=79.15481205712962, w0=72.63366336633673, w1=15.976110672359274\n",
      "SubGD iter. 290/499: loss=79.16691926395363, w0=72.62673267326743, w1=15.973984572573537\n",
      "SubGD iter. 291/499: loss=79.16637962489584, w0=72.62673267326743, w1=15.97237491185245\n",
      "SubGD iter. 292/499: loss=79.15843066170105, w0=72.62673267326743, w1=15.970765251131363\n",
      "SubGD iter. 293/499: loss=79.1504842895139, w0=72.63366336633673, w1=15.975233950938767\n",
      "SubGD iter. 294/499: loss=79.16258757853305, w0=72.62673267326743, w1=15.97310785115303\n",
      "SubGD iter. 295/499: loss=79.1620498034725, w0=72.62673267326743, w1=15.971498190431943\n",
      "SubGD iter. 296/499: loss=79.15410225150173, w0=72.63366336633673, w1=15.975966890239347\n",
      "SubGD iter. 297/499: loss=79.16620881580661, w0=72.62673267326743, w1=15.97384079045361\n",
      "SubGD iter. 298/499: loss=79.16566948244396, w0=72.62673267326743, w1=15.972231129732522\n",
      "SubGD iter. 299/499: loss=79.1577207506896, w0=72.62673267326743, w1=15.970621469011435\n",
      "SubGD iter. 300/499: loss=79.14977460994287, w0=72.63366336633673, w1=15.97509016881884\n",
      "SubGD iter. 301/499: loss=79.1618772564429, w0=72.62673267326743, w1=15.972964069033102\n",
      "SubGD iter. 302/499: loss=79.1613397870775, w0=72.62673267326743, w1=15.971354408312015\n",
      "SubGD iter. 303/499: loss=79.15339246654716, w0=72.63366336633673, w1=15.97582310811942\n",
      "SubGD iter. 304/499: loss=79.16549838833289, w0=72.62673267326743, w1=15.973697008333682\n",
      "SubGD iter. 305/499: loss=79.16495936066538, w0=72.62673267326743, w1=15.972087347612595\n",
      "SubGD iter. 306/499: loss=79.15701086035146, w0=72.62673267326743, w1=15.970477686891508\n",
      "SubGD iter. 307/499: loss=79.14906495104516, w0=72.63366336633673, w1=15.974946386698912\n",
      "SubGD iter. 308/499: loss=79.16116695502606, w0=72.62673267326743, w1=15.972820286913175\n",
      "SubGD iter. 309/499: loss=79.16062979135577, w0=72.62673267326743, w1=15.971210626192088\n",
      "SubGD iter. 310/499: loss=79.15268270226588, w0=72.63366336633673, w1=15.975679325999492\n",
      "SubGD iter. 311/499: loss=79.16478798153248, w0=72.62673267326743, w1=15.973553226213754\n",
      "SubGD iter. 312/499: loss=79.1642492595601, w0=72.62673267326743, w1=15.971943565492667\n",
      "SubGD iter. 313/499: loss=79.1563009906866, w0=72.63366336633673, w1=15.976412265300072\n",
      "SubGD iter. 314/499: loss=79.16840954523893, w0=72.62673267326743, w1=15.974286165514334\n",
      "SubGD iter. 315/499: loss=79.16786926496447, w0=72.62673267326743, w1=15.972676504793247\n",
      "SubGD iter. 316/499: loss=79.15991981630737, w0=72.62673267326743, w1=15.97106684407216\n",
      "SubGD iter. 317/499: loss=79.15197295865788, w0=72.63366336633673, w1=15.975535543879564\n",
      "SubGD iter. 318/499: loss=79.16407759540536, w0=72.62673267326743, w1=15.973409444093827\n",
      "SubGD iter. 319/499: loss=79.16353917912812, w0=72.62673267326743, w1=15.97179978337274\n",
      "SubGD iter. 320/499: loss=79.15559114169504, w0=72.63366336633673, w1=15.976268483180144\n",
      "SubGD iter. 321/499: loss=79.16769905372826, w0=72.62673267326743, w1=15.974142383394407\n",
      "SubGD iter. 322/499: loss=79.16715907914892, w0=72.62673267326743, w1=15.97253272267332\n",
      "SubGD iter. 323/499: loss=79.15920986193223, w0=72.62673267326743, w1=15.970923061952233\n",
      "SubGD iter. 324/499: loss=79.15126323572319, w0=72.63366336633673, w1=15.975391761759637\n",
      "SubGD iter. 325/499: loss=79.16336722995155, w0=72.62673267326743, w1=15.9732656619739\n",
      "SubGD iter. 326/499: loss=79.16282911936946, w0=72.62673267326743, w1=15.971656001252812\n",
      "SubGD iter. 327/499: loss=79.1548813133768, w0=72.63366336633673, w1=15.976124701060217\n",
      "SubGD iter. 328/499: loss=79.16698858289087, w0=72.62673267326743, w1=15.973998601274479\n",
      "SubGD iter. 329/499: loss=79.16644891400666, w0=72.62673267326743, w1=15.972388940553392\n",
      "SubGD iter. 330/499: loss=79.15849992823043, w0=72.62673267326743, w1=15.970779279832305\n",
      "SubGD iter. 331/499: loss=79.1505535334618, w0=72.63366336633673, w1=15.97524797963971\n",
      "SubGD iter. 332/499: loss=79.16265688517103, w0=72.62673267326743, w1=15.973121879853972\n",
      "SubGD iter. 333/499: loss=79.16211908028407, w0=72.62673267326743, w1=15.971512219132885\n",
      "SubGD iter. 334/499: loss=79.15417150573185, w0=72.63366336633673, w1=15.975980918940289\n",
      "SubGD iter. 335/499: loss=79.16627813272677, w0=72.62673267326743, w1=15.973854819154552\n",
      "SubGD iter. 336/499: loss=79.16573876953771, w0=72.62673267326743, w1=15.972245158433465\n",
      "SubGD iter. 337/499: loss=79.15779001520191, w0=72.62673267326743, w1=15.970635497712378\n",
      "SubGD iter. 338/499: loss=79.14984385187373, w0=72.63366336633673, w1=15.975104197519782\n",
      "SubGD iter. 339/499: loss=79.1619465610638, w0=72.62673267326743, w1=15.972978097734044\n",
      "SubGD iter. 340/499: loss=79.16140906187198, w0=72.62673267326743, w1=15.971368437012957\n",
      "SubGD iter. 341/499: loss=79.1534617187602, w0=72.63366336633673, w1=15.975837136820362\n",
      "SubGD iter. 342/499: loss=79.165567703236, w0=72.62673267326743, w1=15.973711037034624\n",
      "SubGD iter. 343/499: loss=79.16502864574205, w0=72.62673267326743, w1=15.972101376313537\n",
      "SubGD iter. 344/499: loss=79.15708012284668, w0=72.62673267326743, w1=15.97049171559245\n",
      "SubGD iter. 345/499: loss=79.14913419095893, w0=72.63366336633673, w1=15.974960415399854\n",
      "SubGD iter. 346/499: loss=79.1612362576299, w0=72.62673267326743, w1=15.972834315614117\n",
      "SubGD iter. 347/499: loss=79.16069906413318, w0=72.62673267326743, w1=15.97122465489303\n",
      "SubGD iter. 348/499: loss=79.15275195246183, w0=72.63366336633673, w1=15.975693354700434\n",
      "SubGD iter. 349/499: loss=79.1648572944185, w0=72.62673267326743, w1=15.973567254914697\n",
      "SubGD iter. 350/499: loss=79.16431854261971, w0=72.62673267326743, w1=15.97195759419361\n",
      "SubGD iter. 351/499: loss=79.15637025116476, w0=72.63366336633673, w1=15.976426294001014\n",
      "SubGD iter. 352/499: loss=79.16847886840712, w0=72.62673267326743, w1=15.974300194215276\n",
      "SubGD iter. 353/499: loss=79.16793855830625, w0=72.62673267326743, w1=15.97269053349419\n",
      "SubGD iter. 354/499: loss=79.1599890870677, w0=72.62673267326743, w1=15.971080872773102\n",
      "SubGD iter. 355/499: loss=79.15204220683677, w0=72.63366336633673, w1=15.975549572580507\n",
      "SubGD iter. 356/499: loss=79.16414690627431, w0=72.62673267326743, w1=15.973423472794769\n",
      "SubGD iter. 357/499: loss=79.16360846017065, w0=72.62673267326743, w1=15.971813812073682\n",
      "SubGD iter. 358/499: loss=79.15566040015614, w0=72.63366336633673, w1=15.976282511881086\n",
      "SubGD iter. 359/499: loss=79.16776837487937, w0=72.62673267326743, w1=15.974156412095349\n",
      "SubGD iter. 360/499: loss=79.16722837047361, w0=72.62673267326743, w1=15.972546751374262\n",
      "SubGD iter. 361/499: loss=79.1592791306755, w0=72.62673267326743, w1=15.970937090653175\n",
      "SubGD iter. 362/499: loss=79.151332481885, w0=72.63366336633673, w1=15.975405790460579\n",
      "SubGD iter. 363/499: loss=79.16343653880342, w0=72.62673267326743, w1=15.973279690674842\n",
      "SubGD iter. 364/499: loss=79.16289839839489, w0=72.62673267326743, w1=15.971670029953755\n",
      "SubGD iter. 365/499: loss=79.15495056982078, w0=72.63366336633673, w1=15.976138729761159\n",
      "SubGD iter. 366/499: loss=79.1670579020249, w0=72.62673267326743, w1=15.974012629975421\n",
      "SubGD iter. 367/499: loss=79.16651820331428, w0=72.62673267326743, w1=15.972402969254334\n",
      "SubGD iter. 368/499: loss=79.1585691949566, w0=72.62673267326743, w1=15.970793308533247\n",
      "SubGD iter. 369/499: loss=79.15062277760654, w0=72.63366336633673, w1=15.975262008340652\n",
      "SubGD iter. 370/499: loss=79.1627261920058, w0=72.62673267326743, w1=15.973135908554914\n",
      "SubGD iter. 371/499: loss=79.16218835729242, w0=72.62673267326743, w1=15.971526247833827\n",
      "SubGD iter. 372/499: loss=79.15424076015876, w0=72.63366336633673, w1=15.975994947641231\n",
      "SubGD iter. 373/499: loss=79.16634744984374, w0=72.62673267326743, w1=15.973868847855494\n",
      "SubGD iter. 374/499: loss=79.16580805682827, w0=72.62673267326743, w1=15.972259187134407\n",
      "SubGD iter. 375/499: loss=79.157859279911, w0=72.62673267326743, w1=15.97064952641332\n",
      "SubGD iter. 376/499: loss=79.14991309400138, w0=72.63366336633673, w1=15.975118226220724\n",
      "SubGD iter. 377/499: loss=79.16201586588151, w0=72.62673267326743, w1=15.972992126434987\n",
      "SubGD iter. 378/499: loss=79.16147833686327, w0=72.62673267326743, w1=15.9713824657139\n",
      "SubGD iter. 379/499: loss=79.15353097117003, w0=72.63366336633673, w1=15.975851165521304\n",
      "SubGD iter. 380/499: loss=79.16563701833589, w0=72.62673267326743, w1=15.973725065735566\n",
      "SubGD iter. 381/499: loss=79.16509793101554, w0=72.62673267326743, w1=15.97211540501448\n",
      "SubGD iter. 382/499: loss=79.1571493855387, w0=72.62673267326743, w1=15.970505744293392\n",
      "SubGD iter. 383/499: loss=79.1492034310695, w0=72.63366336633673, w1=15.974974444100797\n",
      "SubGD iter. 384/499: loss=79.16130556043052, w0=72.62673267326743, w1=15.972848344315059\n",
      "SubGD iter. 385/499: loss=79.1607683371074, w0=72.62673267326743, w1=15.971238683593972\n",
      "SubGD iter. 386/499: loss=79.1528212028546, w0=72.63366336633673, w1=15.975707383401376\n",
      "SubGD iter. 387/499: loss=79.16492660750131, w0=72.62673267326743, w1=15.973581283615639\n",
      "SubGD iter. 388/499: loss=79.16438782587609, w0=72.62673267326743, w1=15.971971622894552\n",
      "SubGD iter. 389/499: loss=79.15643951183971, w0=72.63366336633673, w1=15.976440322701956\n",
      "SubGD iter. 390/499: loss=79.16854819177212, w0=72.62673267326743, w1=15.974314222916218\n",
      "SubGD iter. 391/499: loss=79.16800785184483, w0=72.62673267326743, w1=15.972704562195132\n",
      "SubGD iter. 392/499: loss=79.16005835802484, w0=72.62673267326743, w1=15.971094901474045\n",
      "SubGD iter. 393/499: loss=79.15211145521245, w0=72.63366336633673, w1=15.975563601281449\n",
      "SubGD iter. 394/499: loss=79.16421621734004, w0=72.62673267326743, w1=15.973437501495711\n",
      "SubGD iter. 395/499: loss=79.16367774140997, w0=72.62673267326743, w1=15.971827840774624\n",
      "SubGD iter. 396/499: loss=79.155729658814, w0=72.63366336633673, w1=15.976296540582029\n",
      "SubGD iter. 397/499: loss=79.1678376962273, w0=72.62673267326743, w1=15.974170440796291\n",
      "SubGD iter. 398/499: loss=79.16729766199514, w0=72.62673267326743, w1=15.972560780075204\n",
      "SubGD iter. 399/499: loss=79.15934839961555, w0=72.62673267326743, w1=15.970951119354117\n",
      "SubGD iter. 400/499: loss=79.15140172824361, w0=72.63366336633673, w1=15.975419819161521\n",
      "SubGD iter. 401/499: loss=79.16350584785206, w0=72.62673267326743, w1=15.973293719375784\n",
      "SubGD iter. 402/499: loss=79.16296767761713, w0=72.62673267326743, w1=15.971684058654697\n",
      "SubGD iter. 403/499: loss=79.1550198264616, w0=72.63366336633673, w1=15.976152758462101\n",
      "SubGD iter. 404/499: loss=79.16712722135576, w0=72.62673267326743, w1=15.974026658676364\n",
      "SubGD iter. 405/499: loss=79.16658749281872, w0=72.62673267326743, w1=15.972416997955277\n",
      "SubGD iter. 406/499: loss=79.15863846187958, w0=72.62673267326743, w1=15.97080733723419\n",
      "SubGD iter. 407/499: loss=79.15069202194807, w0=72.63366336633673, w1=15.975276037041594\n",
      "SubGD iter. 408/499: loss=79.1627954990374, w0=72.62673267326743, w1=15.973149937255856\n",
      "SubGD iter. 409/499: loss=79.16225763449759, w0=72.62673267326743, w1=15.97154027653477\n",
      "SubGD iter. 410/499: loss=79.15431001478248, w0=72.63366336633673, w1=15.976008976342174\n",
      "SubGD iter. 411/499: loss=79.16641676715751, w0=72.62673267326743, w1=15.973882876556436\n",
      "SubGD iter. 412/499: loss=79.16587734431563, w0=72.62673267326743, w1=15.972273215835349\n",
      "SubGD iter. 413/499: loss=79.15792854481691, w0=72.62673267326743, w1=15.970663555114262\n",
      "SubGD iter. 414/499: loss=79.14998233632583, w0=72.63366336633673, w1=15.975132254921666\n",
      "SubGD iter. 415/499: loss=79.16208517089603, w0=72.62673267326743, w1=15.973006155135929\n",
      "SubGD iter. 416/499: loss=79.16154761205135, w0=72.62673267326743, w1=15.971396494414842\n",
      "SubGD iter. 417/499: loss=79.15360022377668, w0=72.63366336633673, w1=15.975865194222246\n",
      "SubGD iter. 418/499: loss=79.16570633363258, w0=72.62673267326743, w1=15.973739094436509\n",
      "SubGD iter. 419/499: loss=79.16516721648581, w0=72.62673267326743, w1=15.972129433715422\n",
      "SubGD iter. 420/499: loss=79.15721864842753, w0=72.62673267326743, w1=15.970519772994335\n",
      "SubGD iter. 421/499: loss=79.1492726713769, w0=72.63366336633673, w1=15.974988472801739\n",
      "SubGD iter. 422/499: loss=79.16137486342792, w0=72.62673267326743, w1=15.972862373016001\n",
      "SubGD iter. 423/499: loss=79.1608376102784, w0=72.62673267326743, w1=15.971252712294914\n",
      "SubGD iter. 424/499: loss=79.15289045344416, w0=72.63366336633673, w1=15.975721412102319\n",
      "SubGD iter. 425/499: loss=79.16499592078094, w0=72.62673267326743, w1=15.973595312316581\n",
      "SubGD iter. 426/499: loss=79.16445710932929, w0=72.62673267326743, w1=15.971985651595494\n",
      "SubGD iter. 427/499: loss=79.15650877271146, w0=72.63366336633673, w1=15.976454351402898\n",
      "SubGD iter. 428/499: loss=79.16861751533393, w0=72.62673267326743, w1=15.97432825161716\n",
      "SubGD iter. 429/499: loss=79.16807714558021, w0=72.62673267326743, w1=15.972718590896074\n",
      "SubGD iter. 430/499: loss=79.16012762917876, w0=72.62673267326743, w1=15.971108930174987\n",
      "SubGD iter. 431/499: loss=79.15218070378495, w0=72.63366336633673, w1=15.975577629982391\n",
      "SubGD iter. 432/499: loss=79.16428552860259, w0=72.62673267326743, w1=15.973451530196654\n",
      "SubGD iter. 433/499: loss=79.16374702284608, w0=72.62673267326743, w1=15.971841869475567\n",
      "SubGD iter. 434/499: loss=79.15579891766868, w0=72.63366336633673, w1=15.97631056928297\n",
      "SubGD iter. 435/499: loss=79.16790701777202, w0=72.62673267326743, w1=15.974184469497233\n",
      "SubGD iter. 436/499: loss=79.16736695371343, w0=72.62673267326743, w1=15.972574808776146\n",
      "SubGD iter. 437/499: loss=79.15941766875241, w0=72.62673267326743, w1=15.97096514805506\n",
      "SubGD iter. 438/499: loss=79.15147097479903, w0=72.63366336633673, w1=15.975433847862464\n",
      "SubGD iter. 439/499: loss=79.16357515709753, w0=72.62673267326743, w1=15.973307748076726\n",
      "SubGD iter. 440/499: loss=79.16303695703617, w0=72.62673267326743, w1=15.97169808735564\n",
      "SubGD iter. 441/499: loss=79.15508908329917, w0=72.63366336633673, w1=15.976166787163043\n",
      "SubGD iter. 442/499: loss=79.16719654088342, w0=72.62673267326743, w1=15.974040687377306\n",
      "SubGD iter. 443/499: loss=79.16665678251996, w0=72.62673267326743, w1=15.972431026656219\n",
      "SubGD iter. 444/499: loss=79.15870772899936, w0=72.62673267326743, w1=15.970821365935132\n",
      "SubGD iter. 445/499: loss=79.15076126648641, w0=72.63366336633673, w1=15.975290065742536\n",
      "SubGD iter. 446/499: loss=79.16286480626579, w0=72.62673267326743, w1=15.973163965956799\n",
      "SubGD iter. 447/499: loss=79.16232691189957, w0=72.62673267326743, w1=15.971554305235712\n",
      "SubGD iter. 448/499: loss=79.154379269603, w0=72.63366336633673, w1=15.976023005043116\n",
      "SubGD iter. 449/499: loss=79.1664860846681, w0=72.62673267326743, w1=15.973896905257378\n",
      "SubGD iter. 450/499: loss=79.16594663199977, w0=72.62673267326743, w1=15.972287244536291\n",
      "SubGD iter. 451/499: loss=79.15799780991962, w0=72.62673267326743, w1=15.970677583815204\n",
      "SubGD iter. 452/499: loss=79.1500515788471, w0=72.63366336633673, w1=15.975146283622609\n",
      "SubGD iter. 453/499: loss=79.16215447610733, w0=72.62673267326743, w1=15.973020183836871\n",
      "SubGD iter. 454/499: loss=79.16161688743625, w0=72.62673267326743, w1=15.971410523115784\n",
      "SubGD iter. 455/499: loss=79.15366947658012, w0=72.63366336633673, w1=15.975879222923188\n",
      "SubGD iter. 456/499: loss=79.16577564912608, w0=72.62673267326743, w1=15.97375312313745\n",
      "SubGD iter. 457/499: loss=79.16523650215291, w0=72.62673267326743, w1=15.972143462416364\n",
      "SubGD iter. 458/499: loss=79.15728791151318, w0=72.62673267326743, w1=15.970533801695277\n",
      "SubGD iter. 459/499: loss=79.14934191188108, w0=72.63366336633673, w1=15.975002501502681\n",
      "SubGD iter. 460/499: loss=79.16144416662219, w0=72.62673267326743, w1=15.972876401716944\n",
      "SubGD iter. 461/499: loss=79.16090688364623, w0=72.62673267326743, w1=15.971266740995857\n",
      "SubGD iter. 462/499: loss=79.15295970423054, w0=72.63366336633673, w1=15.97573544080326\n",
      "SubGD iter. 463/499: loss=79.16506523425736, w0=72.62673267326743, w1=15.973609341017523\n",
      "SubGD iter. 464/499: loss=79.16452639297931, w0=72.62673267326743, w1=15.971999680296436\n",
      "SubGD iter. 465/499: loss=79.15657803378001, w0=72.63366336633673, w1=15.97646838010384\n",
      "SubGD iter. 466/499: loss=79.16868683909256, w0=72.62673267326743, w1=15.974342280318103\n",
      "SubGD iter. 467/499: loss=79.16814643951241, w0=72.62673267326743, w1=15.972732619597016\n",
      "SubGD iter. 468/499: loss=79.1601969005295, w0=72.62673267326743, w1=15.97112295887593\n",
      "SubGD iter. 469/499: loss=79.15224995255424, w0=72.63366336633673, w1=15.975591658683333\n",
      "SubGD iter. 470/499: loss=79.16435484006193, w0=72.62673267326743, w1=15.973465558897596\n",
      "SubGD iter. 471/499: loss=79.16381630447901, w0=72.62673267326743, w1=15.971855898176509\n",
      "SubGD iter. 472/499: loss=79.15586817672015, w0=72.63366336633673, w1=15.976324597983913\n",
      "SubGD iter. 473/499: loss=79.16797633951357, w0=72.62673267326743, w1=15.974198498198175\n",
      "SubGD iter. 474/499: loss=79.16743624562856, w0=72.62673267326743, w1=15.972588837477089\n",
      "SubGD iter. 475/499: loss=79.15948693808609, w0=72.62673267326743, w1=15.970979176756002\n",
      "SubGD iter. 476/499: loss=79.15154022155126, w0=72.63366336633673, w1=15.975447876563406\n",
      "SubGD iter. 477/499: loss=79.16364446653981, w0=72.62673267326743, w1=15.973321776777668\n",
      "SubGD iter. 478/499: loss=79.16310623665203, w0=72.62673267326743, w1=15.971712116056581\n",
      "SubGD iter. 479/499: loss=79.15515834033359, w0=72.63366336633673, w1=15.976180815863986\n",
      "SubGD iter. 480/499: loss=79.16726586060787, w0=72.62673267326743, w1=15.974054716078248\n",
      "SubGD iter. 481/499: loss=79.166726072418, w0=72.62673267326743, w1=15.972445055357161\n",
      "SubGD iter. 482/499: loss=79.15877699631596, w0=72.62673267326743, w1=15.970835394636074\n",
      "SubGD iter. 483/499: loss=79.15083051122156, w0=72.63366336633673, w1=15.975304094443478\n",
      "SubGD iter. 484/499: loss=79.162934113691, w0=72.62673267326743, w1=15.97317799465774\n",
      "SubGD iter. 485/499: loss=79.16239618949834, w0=72.62673267326743, w1=15.971568333936654\n",
      "SubGD iter. 486/499: loss=79.15444852462034, w0=72.63366336633673, w1=15.976037033744058\n",
      "SubGD iter. 487/499: loss=79.16655540237548, w0=72.62673267326743, w1=15.97391093395832\n",
      "SubGD iter. 488/499: loss=79.16601591988073, w0=72.62673267326743, w1=15.972301273237234\n",
      "SubGD iter. 489/499: loss=79.15806707521912, w0=72.62673267326743, w1=15.970691612516147\n",
      "SubGD iter. 490/499: loss=79.15012082156515, w0=72.63366336633673, w1=15.97516031232355\n",
      "SubGD iter. 491/499: loss=79.16222378151546, w0=72.62673267326743, w1=15.973034212537813\n",
      "SubGD iter. 492/499: loss=79.16168616301795, w0=72.62673267326743, w1=15.971424551816726\n",
      "SubGD iter. 493/499: loss=79.15373872958038, w0=72.63366336633673, w1=15.97589325162413\n",
      "SubGD iter. 494/499: loss=79.16584496481639, w0=72.62673267326743, w1=15.973767151838393\n",
      "SubGD iter. 495/499: loss=79.16530578801678, w0=72.62673267326743, w1=15.972157491117306\n",
      "SubGD iter. 496/499: loss=79.1573571747956, w0=72.62673267326743, w1=15.97054783039622\n",
      "SubGD iter. 497/499: loss=79.14941115258206, w0=72.63366336633673, w1=15.975016530203623\n",
      "SubGD iter. 498/499: loss=79.16151347001323, w0=72.62673267326743, w1=15.972890430417886\n",
      "SubGD iter. 499/499: loss=79.16097615721085, w0=72.62673267326743, w1=15.971280769696799\n",
      "SubGD: execution time=0.006 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4523f5cdaa0d45fea4507f0b78db51d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    N = len(y)\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        indices = np.random.choice(N, batch_size, replace=False)\n",
    "        y_batch = y[indices]\n",
    "        tx_batch = tx[indices]\n",
    "\n",
    "        subgrad = compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "        w = w - gamma * subgrad\n",
    "        ws.append(w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=2817.658426859133, w0=0.7, w1=0.052160345529710626\n",
      "SubSGD iter. 1/499: loss=2770.4504664387155, w0=1.4, w1=-0.2977775859506066\n",
      "SubSGD iter. 2/499: loss=2715.983585714943, w0=2.0999999999999996, w1=0.04669066091986085\n",
      "SubSGD iter. 3/499: loss=2657.9323262185017, w0=2.8, w1=0.7926763145072578\n",
      "SubSGD iter. 4/499: loss=2612.3102484241085, w0=3.5, w1=0.4073921741791298\n",
      "SubSGD iter. 5/499: loss=2567.2918393891136, w0=4.2, w1=0.0252661896287949\n",
      "SubSGD iter. 6/499: loss=2524.3169544477564, w0=4.9, w1=-0.4797515421955273\n",
      "SubSGD iter. 7/499: loss=2482.906669121165, w0=5.6000000000000005, w1=-1.0527616252101508\n",
      "SubSGD iter. 8/499: loss=2417.794356504318, w0=6.300000000000001, w1=0.48730071317703505\n",
      "SubSGD iter. 9/499: loss=2364.132803817499, w0=7.000000000000001, w1=1.1195751416587258\n",
      "SubSGD iter. 10/499: loss=2319.273310312894, w0=7.700000000000001, w1=0.935414363340406\n",
      "SubSGD iter. 11/499: loss=2277.5149493553376, w0=8.4, w1=0.5036217850569855\n",
      "SubSGD iter. 12/499: loss=2228.2318229648245, w0=9.1, w1=0.847334406240376\n",
      "SubSGD iter. 13/499: loss=2176.1042056235956, w0=9.799999999999999, w1=1.5482684036751286\n",
      "SubSGD iter. 14/499: loss=2124.6655222600434, w0=10.499999999999998, w1=2.2825441471669277\n",
      "SubSGD iter. 15/499: loss=2075.930749937279, w0=11.199999999999998, w1=2.8105999626775766\n",
      "SubSGD iter. 16/499: loss=2028.774651266515, w0=11.899999999999997, w1=3.2341412157315923\n",
      "SubSGD iter. 17/499: loss=1991.0946976138202, w0=12.599999999999996, w1=2.5474465802254556\n",
      "SubSGD iter. 18/499: loss=1947.8358939560571, w0=13.299999999999995, w1=2.603756195270759\n",
      "SubSGD iter. 19/499: loss=1902.4235546355362, w0=13.999999999999995, w1=2.9822959786274903\n",
      "SubSGD iter. 20/499: loss=1859.2996650936332, w0=14.699999999999994, w1=3.1481022381949875\n",
      "SubSGD iter. 21/499: loss=1828.275214803517, w0=15.399999999999993, w1=1.9366793502688073\n",
      "SubSGD iter. 22/499: loss=1791.1287049892223, w0=16.099999999999994, w1=1.5412425583258014\n",
      "SubSGD iter. 23/499: loss=1753.1427212638946, w0=16.799999999999994, w1=1.2972157336166505\n",
      "SubSGD iter. 24/499: loss=1715.706286629745, w0=17.499999999999993, w1=1.0531889089074997\n",
      "SubSGD iter. 25/499: loss=1680.0732846596359, w0=18.199999999999992, w1=0.6872681781771024\n",
      "SubSGD iter. 26/499: loss=1635.6866072245298, w0=18.89999999999999, w1=1.2356626819349132\n",
      "SubSGD iter. 27/499: loss=1593.099988124542, w0=19.59999999999999, w1=1.6755871248190952\n",
      "SubSGD iter. 28/499: loss=1546.7090542789392, w0=20.29999999999999, w1=2.633722215720902\n",
      "SubSGD iter. 29/499: loss=1508.2136721477125, w0=20.99999999999999, w1=2.766045742074741\n",
      "SubSGD iter. 30/499: loss=1474.149112616809, w0=21.69999999999999, w1=2.429682784398664\n",
      "SubSGD iter. 31/499: loss=1430.5576562926494, w0=22.399999999999988, w1=3.3088550966294705\n",
      "SubSGD iter. 32/499: loss=1390.6020537631948, w0=23.099999999999987, w1=3.8498121486006127\n",
      "SubSGD iter. 33/499: loss=1350.26740605698, w0=23.799999999999986, w1=4.567975472631801\n",
      "SubSGD iter. 34/499: loss=1312.6756284117885, w0=24.499999999999986, w1=4.991516725685816\n",
      "SubSGD iter. 35/499: loss=1272.6159248735723, w0=25.199999999999985, w1=6.004195067038583\n",
      "SubSGD iter. 36/499: loss=1235.7575594435862, w0=25.899999999999984, w1=6.617187564222142\n",
      "SubSGD iter. 37/499: loss=1202.9610875090398, w0=26.599999999999984, w1=6.466730887771015\n",
      "SubSGD iter. 38/499: loss=1170.5334958977226, w0=27.299999999999983, w1=6.346839074282684\n",
      "SubSGD iter. 39/499: loss=1134.9049238360742, w0=27.999999999999982, w1=7.071859264363488\n",
      "SubSGD iter. 40/499: loss=1100.2920060504507, w0=28.69999999999998, w1=7.7968794544442925\n",
      "SubSGD iter. 41/499: loss=1070.0898819131621, w0=29.39999999999998, w1=7.414753469893958\n",
      "SubSGD iter. 42/499: loss=1036.685488572355, w0=30.09999999999998, w1=8.146718063401593\n",
      "SubSGD iter. 43/499: loss=1005.0194560484165, w0=30.79999999999998, w1=8.570259316455608\n",
      "SubSGD iter. 44/499: loss=975.3591314291587, w0=31.49999999999998, w1=8.41980264000448\n",
      "SubSGD iter. 45/499: loss=946.3052223465569, w0=32.19999999999998, w1=8.23564186168616\n",
      "SubSGD iter. 46/499: loss=915.7013103104332, w0=32.899999999999984, w1=8.854775257630827\n",
      "SubSGD iter. 47/499: loss=888.0705203768742, w0=33.59999999999999, w1=8.458799014408994\n",
      "SubSGD iter. 48/499: loss=862.5048709808827, w0=34.29999999999999, w1=7.618771442949183\n",
      "SubSGD iter. 49/499: loss=833.0643959046791, w0=34.99999999999999, w1=8.211089404217361\n",
      "SubSGD iter. 50/499: loss=804.4188401454603, w0=35.699999999999996, w1=8.824081901400922\n",
      "SubSGD iter. 51/499: loss=781.7163211372839, w0=36.4, w1=7.4701250073676935\n",
      "SubSGD iter. 52/499: loss=759.8305742160162, w0=37.1, w1=6.432610813554152\n",
      "SubSGD iter. 53/499: loss=737.6832991693873, w0=37.800000000000004, w1=5.72910589516329\n",
      "SubSGD iter. 54/499: loss=716.4793819191481, w0=38.50000000000001, w1=5.032521143922527\n",
      "SubSGD iter. 55/499: loss=687.627480434247, w0=39.20000000000001, w1=5.778506797509924\n",
      "SubSGD iter. 56/499: loss=659.8220735447042, w0=39.90000000000001, w1=6.524492451097321\n",
      "SubSGD iter. 57/499: loss=633.1682831352505, w0=40.600000000000016, w1=7.242655775128509\n",
      "SubSGD iter. 58/499: loss=605.7401284960772, w0=41.30000000000002, w1=8.60802522779212\n",
      "SubSGD iter. 59/499: loss=584.5459273565477, w0=42.00000000000002, w1=8.05391815379554\n",
      "SubSGD iter. 60/499: loss=561.7707146866892, w0=42.700000000000024, w1=8.252679019614064\n",
      "SubSGD iter. 61/499: loss=538.1620642243331, w0=43.40000000000003, w1=9.04784874473141\n",
      "SubSGD iter. 62/499: loss=518.1941537627575, w0=44.10000000000003, w1=8.49374167073483\n",
      "SubSGD iter. 63/499: loss=499.49686302065516, w0=44.80000000000003, w1=7.790236752343967\n",
      "SubSGD iter. 64/499: loss=477.43718580661294, w0=45.500000000000036, w1=8.409370148288634\n",
      "SubSGD iter. 65/499: loss=455.19881857383257, w0=46.20000000000004, w1=9.648686449266634\n",
      "SubSGD iter. 66/499: loss=436.64344277359356, w0=46.90000000000004, w1=9.208491194559663\n",
      "SubSGD iter. 67/499: loss=418.8583527090978, w0=47.600000000000044, w1=8.73044299213354\n",
      "SubSGD iter. 68/499: loss=399.820767129686, w0=48.30000000000005, w1=9.085470469663365\n",
      "SubSGD iter. 69/499: loss=380.4235634109944, w0=49.00000000000005, w1=10.266275170363262\n",
      "SubSGD iter. 70/499: loss=363.11617937552813, w0=49.70000000000005, w1=10.272703051241608\n",
      "SubSGD iter. 71/499: loss=346.68392372109565, w0=50.400000000000055, w1=9.876726808019775\n",
      "SubSGD iter. 72/499: loss=330.39954368386736, w0=51.10000000000006, w1=9.844297800252415\n",
      "SubSGD iter. 73/499: loss=321.7026704810379, w0=51.80000000000006, w1=7.073998103363426\n",
      "SubSGD iter. 74/499: loss=308.1984297096387, w0=52.500000000000064, w1=6.6343096982782415\n",
      "SubSGD iter. 75/499: loss=296.2303969524906, w0=53.20000000000007, w1=6.021511527276829\n",
      "SubSGD iter. 76/499: loss=280.8315799973609, w0=53.90000000000007, w1=6.2326759218430325\n",
      "SubSGD iter. 77/499: loss=269.93582320678405, w0=54.60000000000007, w1=5.6483633842971415\n",
      "SubSGD iter. 78/499: loss=256.08042143025267, w0=55.300000000000075, w1=5.736890897786267\n",
      "SubSGD iter. 79/499: loss=242.38961385038002, w0=56.00000000000008, w1=5.889784654900849\n",
      "SubSGD iter. 80/499: loss=228.9953423388117, w0=56.70000000000008, w1=6.0863047376793515\n",
      "SubSGD iter. 81/499: loss=218.00760502949606, w0=57.400000000000084, w1=5.902838958628932\n",
      "SubSGD iter. 82/499: loss=208.69571174184657, w0=58.10000000000009, w1=5.5068627154071\n",
      "SubSGD iter. 83/499: loss=191.68021973378632, w0=58.80000000000009, w1=6.746179016385101\n",
      "SubSGD iter. 84/499: loss=179.81975839185017, w0=59.50000000000009, w1=7.090647263255568\n",
      "SubSGD iter. 85/499: loss=167.70646587823416, w0=60.200000000000095, w1=7.6829652245237465\n",
      "SubSGD iter. 86/499: loss=159.22148418744226, w0=60.9000000000001, w1=7.403036232087283\n",
      "SubSGD iter. 87/499: loss=147.56968155807306, w0=61.6000000000001, w1=8.23637381464686\n",
      "SubSGD iter. 88/499: loss=136.96373686191964, w0=62.300000000000104, w1=9.141548917833925\n",
      "SubSGD iter. 89/499: loss=129.5404553074752, w0=63.00000000000011, w1=8.861619925397461\n",
      "SubSGD iter. 90/499: loss=135.0578089693792, w0=63.70000000000011, w1=5.4884762478077835\n",
      "SubSGD iter. 91/499: loss=122.43786182578198, w0=64.4000000000001, w1=6.613606207938091\n",
      "SubSGD iter. 92/499: loss=119.45750794220696, w0=65.10000000000011, w1=5.874273408494147\n",
      "SubSGD iter. 93/499: loss=113.20750827622564, w0=65.80000000000011, w1=5.916599965097637\n",
      "SubSGD iter. 94/499: loss=104.54021378325754, w0=66.50000000000011, w1=6.5686568625400925\n",
      "SubSGD iter. 95/499: loss=97.51273230222296, w0=67.20000000000012, w1=7.035238988506667\n",
      "SubSGD iter. 96/499: loss=100.44797931042088, w0=66.50000000000011, w1=7.605199113042653\n",
      "SubSGD iter. 97/499: loss=92.18536027262672, w0=67.20000000000012, w1=8.723509333654135\n",
      "SubSGD iter. 98/499: loss=95.64901995604674, w0=66.50000000000011, w1=9.563536905113946\n",
      "SubSGD iter. 99/499: loss=89.56002146304024, w0=67.20000000000012, w1=10.731867705631414\n",
      "SubSGD iter. 100/499: loss=94.72547387679347, w0=66.50000000000011, w1=10.47115548424955\n",
      "SubSGD iter. 101/499: loss=89.51451710068696, w0=67.20000000000012, w1=11.063473445517728\n",
      "SubSGD iter. 102/499: loss=84.99867878132291, w0=67.90000000000012, w1=11.341600414319416\n",
      "SubSGD iter. 103/499: loss=89.73417912320515, w0=67.20000000000012, w1=11.698325932675253\n",
      "SubSGD iter. 104/499: loss=85.77061171106374, w0=67.90000000000012, w1=12.314712881512502\n",
      "SubSGD iter. 105/499: loss=91.11315139428066, w0=67.20000000000012, w1=12.823213999252335\n",
      "SubSGD iter. 106/499: loss=85.72703400695293, w0=67.90000000000012, w1=12.280197537887236\n",
      "SubSGD iter. 107/499: loss=82.1597088297703, w0=68.60000000000012, w1=12.635225015417062\n",
      "SubSGD iter. 108/499: loss=79.85837476792094, w0=69.30000000000013, w1=13.298369332460108\n",
      "SubSGD iter. 109/499: loss=83.62702545935441, w0=68.60000000000012, w1=13.37918363794882\n",
      "SubSGD iter. 110/499: loss=80.9208371334579, w0=69.30000000000013, w1=13.727150684339234\n",
      "SubSGD iter. 111/499: loss=78.19337657655362, w0=70.00000000000013, w1=13.859474210693072\n",
      "SubSGD iter. 112/499: loss=76.73177431511526, w0=70.70000000000013, w1=14.238013994049805\n",
      "SubSGD iter. 113/499: loss=76.72422900283858, w0=70.00000000000013, w1=13.279878903147997\n",
      "SubSGD iter. 114/499: loss=75.78110825260588, w0=70.70000000000013, w1=13.926026136535217\n",
      "SubSGD iter. 115/499: loss=71.67609310934061, w0=71.40000000000013, w1=13.126195402472508\n",
      "SubSGD iter. 116/499: loss=68.86507889776261, w0=72.10000000000014, w1=12.447848406497965\n",
      "SubSGD iter. 117/499: loss=72.13843207490956, w0=71.40000000000013, w1=13.336680230664458\n",
      "SubSGD iter. 118/499: loss=77.4764128242548, w0=70.70000000000013, w1=14.462612644165628\n",
      "SubSGD iter. 119/499: loss=76.60116777100076, w0=71.40000000000013, w1=14.806325265349018\n",
      "SubSGD iter. 120/499: loss=78.29377839238224, w0=72.10000000000014, w1=15.601494990466366\n",
      "SubSGD iter. 121/499: loss=79.11768441073708, w0=71.40000000000013, w1=15.42314286908655\n",
      "SubSGD iter. 122/499: loss=81.76621304004108, w0=70.70000000000013, w1=15.543647420565593\n",
      "SubSGD iter. 123/499: loss=84.91926301627227, w0=70.00000000000013, w1=15.664151972044635\n",
      "SubSGD iter. 124/499: loss=82.51363519945242, w0=70.70000000000013, w1=15.706478528648127\n",
      "SubSGD iter. 125/499: loss=86.10237209620203, w0=71.40000000000013, w1=16.799103042973922\n",
      "SubSGD iter. 126/499: loss=91.08467059398937, w0=70.70000000000013, w1=17.277151245400045\n",
      "SubSGD iter. 127/499: loss=96.57829447907554, w0=71.40000000000013, w1=18.395461466011525\n",
      "SubSGD iter. 128/499: loss=94.7797154013698, w0=72.10000000000014, w1=18.371495626208436\n",
      "SubSGD iter. 129/499: loss=88.49636821863274, w0=72.80000000000014, w1=17.632162826764493\n",
      "SubSGD iter. 130/499: loss=87.95501006166866, w0=73.50000000000014, w1=17.64747049347663\n",
      "SubSGD iter. 131/499: loss=87.57375176010322, w0=74.20000000000014, w1=17.61277963413516\n",
      "SubSGD iter. 132/499: loss=88.52203741579264, w0=73.50000000000014, w1=17.73267144762349\n",
      "SubSGD iter. 133/499: loss=88.0677140896773, w0=72.80000000000014, w1=17.566865188055992\n",
      "SubSGD iter. 134/499: loss=85.3476803014016, w0=72.10000000000014, w1=16.947731792111327\n",
      "SubSGD iter. 135/499: loss=84.87348536244346, w0=72.80000000000014, w1=17.05803182557212\n",
      "SubSGD iter. 136/499: loss=84.04301389563685, w0=72.10000000000014, w1=16.722803770268865\n",
      "SubSGD iter. 137/499: loss=78.75741596621, w0=72.80000000000014, w1=15.93857104222954\n",
      "SubSGD iter. 138/499: loss=77.9454408551365, w0=73.50000000000014, w1=15.90388018288807\n",
      "SubSGD iter. 139/499: loss=79.01237617464261, w0=74.20000000000014, w1=16.148192906597206\n",
      "SubSGD iter. 140/499: loss=80.58985010029106, w0=73.50000000000014, w1=16.419673088579785\n",
      "SubSGD iter. 141/499: loss=84.77981233377089, w0=72.80000000000014, w1=17.042459495400077\n",
      "SubSGD iter. 142/499: loss=84.8567192758378, w0=72.10000000000014, w1=16.864107374020264\n",
      "SubSGD iter. 143/499: loss=84.24421942664745, w0=72.80000000000014, w1=16.95263488750939\n",
      "SubSGD iter. 144/499: loss=88.63392012405998, w0=72.10000000000014, w1=17.47959192327824\n",
      "SubSGD iter. 145/499: loss=88.82659080237035, w0=72.80000000000014, w1=17.68202881331924\n",
      "SubSGD iter. 146/499: loss=86.12337855124879, w0=72.10000000000014, w1=17.07749670746508\n",
      "SubSGD iter. 147/499: loss=82.65693343774542, w0=72.80000000000014, w1=16.6780389350785\n",
      "SubSGD iter. 148/499: loss=77.84724001200084, w0=73.50000000000014, w1=15.88366959058772\n",
      "SubSGD iter. 149/499: loss=78.66608221561214, w0=74.20000000000014, w1=16.080014184104947\n",
      "SubSGD iter. 150/499: loss=81.34462157703248, w0=73.50000000000014, w1=16.55806238653107\n",
      "SubSGD iter. 151/499: loss=83.36466125344424, w0=72.80000000000014, w1=16.802089211240222\n",
      "SubSGD iter. 152/499: loss=81.58252845056872, w0=72.10000000000014, w1=16.272388237178106\n",
      "SubSGD iter. 153/499: loss=78.67849503360897, w0=72.80000000000014, w1=15.922450305697788\n",
      "SubSGD iter. 154/499: loss=81.98265945401313, w0=72.10000000000014, w1=16.348236452988527\n",
      "SubSGD iter. 155/499: loss=87.45298708749222, w0=71.40000000000013, w1=17.028835630644608\n",
      "SubSGD iter. 156/499: loss=88.17111421134152, w0=72.10000000000014, w1=17.40737541400134\n",
      "SubSGD iter. 157/499: loss=86.81818501440675, w0=72.80000000000014, w1=17.37268455465987\n",
      "SubSGD iter. 158/499: loss=90.19788251114915, w0=72.10000000000014, w1=17.717861642384868\n",
      "SubSGD iter. 159/499: loss=90.0335638167852, w0=72.80000000000014, w1=17.861192232979384\n",
      "SubSGD iter. 160/499: loss=84.35456508643058, w0=72.10000000000014, w1=16.777316836288083\n",
      "SubSGD iter. 161/499: loss=82.07648445446097, w0=71.40000000000013, w1=16.052296646207278\n",
      "SubSGD iter. 162/499: loss=86.04634596877557, w0=72.10000000000014, w1=17.0647349840737\n",
      "SubSGD iter. 163/499: loss=85.13941356962002, w0=72.80000000000014, w1=17.10202229569157\n",
      "SubSGD iter. 164/499: loss=83.8935832801164, w0=73.50000000000014, w1=17.00174519645136\n",
      "SubSGD iter. 165/499: loss=83.19516090816565, w0=72.80000000000014, w1=16.772623504164603\n",
      "SubSGD iter. 166/499: loss=82.44626551445786, w0=73.50000000000014, w1=16.754044045265726\n",
      "SubSGD iter. 167/499: loss=77.31825550728146, w0=72.80000000000014, w1=15.635733824654244\n",
      "SubSGD iter. 168/499: loss=78.31622700993894, w0=73.50000000000014, w1=15.979446445837635\n",
      "SubSGD iter. 169/499: loss=75.00414062784166, w0=74.20000000000014, w1=15.292751810331499\n",
      "SubSGD iter. 170/499: loss=73.11819935652025, w0=73.50000000000014, w1=14.783565966385247\n",
      "SubSGD iter. 171/499: loss=75.59668184207848, w0=74.20000000000014, w1=15.429713199772468\n",
      "SubSGD iter. 172/499: loss=76.23941033731792, w0=73.50000000000014, w1=15.539887316653209\n",
      "SubSGD iter. 173/499: loss=79.43777722942752, w0=72.80000000000014, w1=16.075406999479416\n",
      "SubSGD iter. 174/499: loss=82.26097922449563, w0=73.50000000000014, w1=16.721554232866637\n",
      "SubSGD iter. 175/499: loss=77.18821738596952, w0=74.20000000000014, w1=15.778047749329517\n",
      "SubSGD iter. 176/499: loss=79.43773658771185, w0=73.50000000000014, w1=16.20128717410203\n",
      "SubSGD iter. 177/499: loss=75.18040927091269, w0=72.80000000000014, w1=15.14488594272314\n",
      "SubSGD iter. 178/499: loss=74.05387211758, w0=72.10000000000014, w1=14.552567981454963\n",
      "SubSGD iter. 179/499: loss=74.79322127518893, w0=71.40000000000013, w1=14.2918557600731\n",
      "SubSGD iter. 180/499: loss=75.42562285001044, w0=72.10000000000014, w1=14.923021100067952\n",
      "SubSGD iter. 181/499: loss=71.88573732417872, w0=72.80000000000014, w1=14.24467410409341\n",
      "SubSGD iter. 182/499: loss=73.62627446148176, w0=72.10000000000014, w1=14.42883488241173\n",
      "SubSGD iter. 183/499: loss=76.44353862103755, w0=72.80000000000014, w1=15.441513223764497\n",
      "SubSGD iter. 184/499: loss=75.71937453607435, w0=73.50000000000014, w1=15.42293376486562\n",
      "SubSGD iter. 185/499: loss=72.1642739284479, w0=72.80000000000014, w1=14.330309250539825\n",
      "SubSGD iter. 186/499: loss=76.25237633470792, w0=72.10000000000014, w1=15.130139984602534\n",
      "SubSGD iter. 187/499: loss=76.17322881848052, w0=72.80000000000014, w1=15.379738447289713\n",
      "SubSGD iter. 188/499: loss=75.90536837710387, w0=72.10000000000014, w1=15.044510391986458\n",
      "SubSGD iter. 189/499: loss=81.54950157179682, w0=71.40000000000013, w1=15.946142656399216\n",
      "SubSGD iter. 190/499: loss=83.29130383456744, w0=72.10000000000014, w1=16.58907235516301\n",
      "SubSGD iter. 191/499: loss=79.1404103095878, w0=72.80000000000014, w1=16.01606227214839\n",
      "SubSGD iter. 192/499: loss=76.87903602937234, w0=73.50000000000014, w1=15.679699314472312\n",
      "SubSGD iter. 193/499: loss=75.6363030109216, w0=74.20000000000014, w1=15.438719399805665\n",
      "SubSGD iter. 194/499: loss=76.48156119354321, w0=74.90000000000015, w1=15.552539726619978\n",
      "SubSGD iter. 195/499: loss=81.21753896297211, w0=75.60000000000015, w1=16.347709451737327\n",
      "SubSGD iter. 196/499: loss=77.31683506510336, w0=74.90000000000015, w1=15.733795038359744\n",
      "SubSGD iter. 197/499: loss=74.71632082550161, w0=74.20000000000014, w1=15.224609194413492\n",
      "SubSGD iter. 198/499: loss=73.44434346925946, w0=73.50000000000014, w1=14.869581716883667\n",
      "SubSGD iter. 199/499: loss=70.59383143729978, w0=72.80000000000014, w1=13.813180485504777\n",
      "SubSGD iter. 200/499: loss=70.96772770206242, w0=73.50000000000014, w1=14.157648732375245\n",
      "SubSGD iter. 201/499: loss=68.59301692206408, w0=72.80000000000014, w1=12.962909895270819\n",
      "SubSGD iter. 202/499: loss=70.9420264678601, w0=72.10000000000014, w1=13.514881327208498\n",
      "SubSGD iter. 203/499: loss=69.03195680796766, w0=72.80000000000014, w1=13.178518369532421\n",
      "SubSGD iter. 204/499: loss=69.49851856121019, w0=73.50000000000014, w1=13.645100495498996\n",
      "SubSGD iter. 205/499: loss=69.26193390440044, w0=74.20000000000014, w1=13.612671487731635\n",
      "SubSGD iter. 206/499: loss=70.07321919225092, w0=73.50000000000014, w1=13.856698312440786\n",
      "SubSGD iter. 207/499: loss=72.9482954791104, w0=72.80000000000014, w1=14.560203230831648\n",
      "SubSGD iter. 208/499: loss=73.71194702914708, w0=73.50000000000014, w1=14.938743014188379\n",
      "SubSGD iter. 209/499: loss=73.10192062920659, w0=72.80000000000014, w1=14.603514958885125\n",
      "SubSGD iter. 210/499: loss=76.79428965071719, w0=72.10000000000014, w1=15.260395926638088\n",
      "SubSGD iter. 211/499: loss=80.37132051799125, w0=71.40000000000013, w1=15.700084331723273\n",
      "SubSGD iter. 212/499: loss=87.025364485176, w0=70.70000000000013, w1=16.588916155889766\n",
      "SubSGD iter. 213/499: loss=89.9386889394613, w0=71.40000000000013, w1=17.43010632411441\n",
      "SubSGD iter. 214/499: loss=85.86227162581332, w0=72.10000000000014, w1=17.034130080892577\n",
      "SubSGD iter. 215/499: loss=83.97588432939986, w0=72.80000000000014, w1=16.907115635664553\n",
      "SubSGD iter. 216/499: loss=83.22449014466265, w0=73.50000000000014, w1=16.888536176765676\n",
      "SubSGD iter. 217/499: loss=88.23247928083835, w0=72.80000000000014, w1=17.59204109515654\n",
      "SubSGD iter. 218/499: loss=90.16237001807859, w0=72.10000000000014, w1=17.71254564663558\n",
      "SubSGD iter. 219/499: loss=88.36531821792391, w0=72.80000000000014, w1=17.61226854739537\n",
      "SubSGD iter. 220/499: loss=84.93775679997451, w0=72.10000000000014, w1=16.87799280390357\n",
      "SubSGD iter. 221/499: loss=80.02864345403975, w0=72.80000000000014, w1=16.191298168397434\n",
      "SubSGD iter. 222/499: loss=84.16776367631819, w0=73.50000000000014, w1=17.047520220901973\n",
      "SubSGD iter. 223/499: loss=82.51210609604699, w0=74.20000000000014, w1=16.7920883398004\n",
      "SubSGD iter. 224/499: loss=83.84047430737867, w0=73.50000000000014, w1=16.992837876849652\n",
      "SubSGD iter. 225/499: loss=84.55223752850551, w0=74.20000000000014, w1=17.13616846744417\n",
      "SubSGD iter. 226/499: loss=82.72413992601577, w0=74.90000000000015, w1=16.77024773671377\n",
      "SubSGD iter. 227/499: loss=80.42943108061355, w0=75.60000000000015, w1=16.197237653699148\n",
      "SubSGD iter. 228/499: loss=81.87636797635172, w0=74.90000000000015, w1=16.620477078471662\n",
      "SubSGD iter. 229/499: loss=81.64278176808968, w0=74.20000000000014, w1=16.63905653737054\n",
      "SubSGD iter. 230/499: loss=78.96700753136687, w0=73.50000000000014, w1=16.109355563308423\n",
      "SubSGD iter. 231/499: loss=74.08793628468304, w0=74.20000000000014, w1=15.071841369494882\n",
      "SubSGD iter. 232/499: loss=76.33712159254098, w0=73.50000000000014, w1=15.56152490289147\n",
      "SubSGD iter. 233/499: loss=81.11350477977302, w0=72.80000000000014, w1=16.397563760164285\n",
      "SubSGD iter. 234/499: loss=76.04235575308867, w0=73.50000000000014, w1=15.495931495751528\n",
      "SubSGD iter. 235/499: loss=74.59663564394657, w0=72.80000000000014, w1=15.000305235282696\n",
      "SubSGD iter. 236/499: loss=73.33904518931446, w0=72.10000000000014, w1=14.34312253208771\n",
      "SubSGD iter. 237/499: loss=72.09241755809285, w0=72.80000000000014, w1=14.30843167274624\n",
      "SubSGD iter. 238/499: loss=74.65504280715786, w0=72.10000000000014, w1=14.719506857288465\n",
      "SubSGD iter. 239/499: loss=71.25321055655367, w0=72.80000000000014, w1=14.041159861313922\n",
      "SubSGD iter. 240/499: loss=70.78043018555978, w0=72.10000000000014, w1=13.448841900045744\n",
      "SubSGD iter. 241/499: loss=68.79854433410443, w0=72.80000000000014, w1=13.06671591549541\n",
      "SubSGD iter. 242/499: loss=71.58895915071949, w0=72.10000000000014, w1=13.763300666736173\n",
      "SubSGD iter. 243/499: loss=70.92262767053111, w0=72.80000000000014, w1=13.92910692630367\n",
      "SubSGD iter. 244/499: loss=71.68441012480956, w0=73.50000000000014, w1=14.379286672509963\n",
      "SubSGD iter. 245/499: loss=73.42239379303405, w0=74.20000000000014, w1=14.90346722396168\n",
      "SubSGD iter. 246/499: loss=73.07170951293382, w0=73.50000000000014, w1=14.771143697607842\n",
      "SubSGD iter. 247/499: loss=73.06371044586047, w0=72.80000000000014, w1=14.592791576228027\n",
      "SubSGD iter. 248/499: loss=71.45314816014732, w0=72.10000000000014, w1=13.71306144639555\n",
      "SubSGD iter. 249/499: loss=68.3984682422009, w0=72.80000000000014, w1=12.85921517597028\n",
      "SubSGD iter. 250/499: loss=68.61080167540807, w0=72.10000000000014, w1=12.254683070116121\n",
      "SubSGD iter. 251/499: loss=66.95596162900186, w0=72.80000000000014, w1=11.70057599611954\n",
      "SubSGD iter. 252/499: loss=67.32572649992386, w0=73.50000000000014, w1=12.605751099306604\n",
      "SubSGD iter. 253/499: loss=66.28518335913971, w0=74.20000000000014, w1=11.866418299862659\n",
      "SubSGD iter. 254/499: loss=67.47776817396357, w0=74.90000000000015, w1=12.584581623893847\n",
      "SubSGD iter. 255/499: loss=68.55392975676432, w0=75.60000000000015, w1=12.737475381008428\n",
      "SubSGD iter. 256/499: loss=67.93770634423898, w0=74.90000000000015, w1=12.85736719449676\n",
      "SubSGD iter. 257/499: loss=67.64659490854841, w0=74.20000000000014, w1=12.882664959885602\n",
      "SubSGD iter. 258/499: loss=66.80068101449635, w0=73.50000000000014, w1=12.225482256690617\n",
      "SubSGD iter. 259/499: loss=67.41633498372889, w0=74.20000000000014, w1=12.753538072201266\n",
      "SubSGD iter. 260/499: loss=70.48040273259929, w0=74.90000000000015, w1=13.934342772901163\n",
      "SubSGD iter. 261/499: loss=70.23822473715254, w0=75.60000000000015, w1=13.53836652967933\n",
      "SubSGD iter. 262/499: loss=70.35704948065481, w0=74.90000000000015, w1=13.891482281246644\n",
      "SubSGD iter. 263/499: loss=71.34361838218132, w0=74.20000000000014, w1=14.322492965995258\n",
      "SubSGD iter. 264/499: loss=69.68109931209601, w0=74.90000000000015, w1=13.644145970020714\n",
      "SubSGD iter. 265/499: loss=67.93015200313437, w0=74.20000000000014, w1=13.030231556643132\n",
      "SubSGD iter. 266/499: loss=68.5993063240175, w0=73.50000000000014, w1=13.274258381352283\n",
      "SubSGD iter. 267/499: loss=68.07073281425463, w0=72.80000000000014, w1=12.669726275498123\n",
      "SubSGD iter. 268/499: loss=70.81736819556095, w0=72.10000000000014, w1=13.464095619988903\n",
      "SubSGD iter. 269/499: loss=70.5789202386309, w0=72.80000000000014, w1=13.807808241172294\n",
      "SubSGD iter. 270/499: loss=71.56810856812864, w0=72.10000000000014, w1=13.755647895642584\n",
      "SubSGD iter. 271/499: loss=71.20711186789426, w0=72.80000000000014, w1=14.025786345932254\n",
      "SubSGD iter. 272/499: loss=71.32520496671233, w0=73.50000000000014, w1=14.270099069641388\n",
      "SubSGD iter. 273/499: loss=70.10184847926584, w0=74.20000000000014, w1=13.92016113816107\n",
      "SubSGD iter. 274/499: loss=72.76935607754736, w0=74.90000000000015, w1=14.638324462192259\n",
      "SubSGD iter. 275/499: loss=75.67032505679504, w0=74.20000000000014, w1=15.446438203234191\n",
      "SubSGD iter. 276/499: loss=73.70612884980042, w0=73.50000000000014, w1=14.937252359287939\n",
      "SubSGD iter. 277/499: loss=76.14899341526716, w0=74.20000000000014, w1=15.553639308125188\n",
      "SubSGD iter. 278/499: loss=80.15271528074842, w0=73.50000000000014, w1=16.337872036164512\n",
      "SubSGD iter. 279/499: loss=78.03742411139532, w0=72.80000000000014, w1=15.789477532406702\n",
      "SubSGD iter. 280/499: loss=82.27124857089076, w0=72.10000000000014, w1=16.402275703408115\n",
      "SubSGD iter. 281/499: loss=78.78159672423963, w0=71.40000000000013, w1=15.345874472029225\n",
      "SubSGD iter. 282/499: loss=75.03507063954758, w0=72.10000000000014, w1=14.821241547317486\n",
      "SubSGD iter. 283/499: loss=75.77809766545565, w0=72.80000000000014, w1=15.28782367328406\n",
      "SubSGD iter. 284/499: loss=76.01707359554659, w0=73.50000000000014, w1=15.49026056332506\n",
      "SubSGD iter. 285/499: loss=77.97165579792835, w0=74.20000000000014, w1=15.940440309531354\n",
      "SubSGD iter. 286/499: loss=81.66979185254496, w0=74.90000000000015, w1=16.583370008295148\n",
      "SubSGD iter. 287/499: loss=84.4926027273973, w0=74.20000000000014, w1=17.126386469660247\n",
      "SubSGD iter. 288/499: loss=88.88151847771708, w0=74.90000000000015, w1=17.758660898141937\n",
      "SubSGD iter. 289/499: loss=91.00614804701164, w0=74.20000000000014, w1=18.115386416497774\n",
      "SubSGD iter. 290/499: loss=86.72138012103677, w0=73.50000000000014, w1=17.45820371330279\n",
      "SubSGD iter. 291/499: loss=89.98204199193707, w0=72.80000000000014, w1=17.853640505245796\n",
      "SubSGD iter. 292/499: loss=87.1025744622758, w0=73.50000000000014, w1=17.51727754756972\n",
      "SubSGD iter. 293/499: loss=90.6318998642985, w0=72.80000000000014, w1=17.948288232318333\n",
      "SubSGD iter. 294/499: loss=91.40945196578464, w0=73.50000000000014, w1=18.150725122359333\n",
      "SubSGD iter. 295/499: loss=87.6614088810303, w0=74.20000000000014, w1=17.626092197647594\n",
      "SubSGD iter. 296/499: loss=89.04467060626189, w0=73.50000000000014, w1=17.810252975965913\n",
      "SubSGD iter. 297/499: loss=82.93088368330987, w0=72.80000000000014, w1=16.72637757927461\n",
      "SubSGD iter. 298/499: loss=82.67019745258139, w0=72.10000000000014, w1=16.476096462812556\n",
      "SubSGD iter. 299/499: loss=81.36180640555828, w0=72.80000000000014, w1=16.443667455045198\n",
      "SubSGD iter. 300/499: loss=87.19169786462422, w0=72.10000000000014, w1=17.25178119608713\n",
      "SubSGD iter. 301/499: loss=84.5038655192258, w0=72.80000000000014, w1=16.996349314985558\n",
      "SubSGD iter. 302/499: loss=88.91791696215714, w0=73.50000000000014, w1=17.791519040102905\n",
      "SubSGD iter. 303/499: loss=90.10967842667056, w0=72.80000000000014, w1=17.872333345591617\n",
      "SubSGD iter. 304/499: loss=72.0926010846742, w0=73.50000000000014, w1=14.49918966800194\n",
      "SubSGD iter. 305/499: loss=74.87200235168771, w0=72.80000000000014, w1=15.069149792537925\n",
      "SubSGD iter. 306/499: loss=74.33628000729917, w0=73.50000000000014, w1=15.095522443162745\n",
      "SubSGD iter. 307/499: loss=71.71283610328999, w0=72.80000000000014, w1=14.19034733997568\n",
      "SubSGD iter. 308/499: loss=71.95926843728952, w0=73.50000000000014, w1=14.46048579026535\n",
      "SubSGD iter. 309/499: loss=73.61928594227173, w0=72.80000000000014, w1=14.745660284814644\n",
      "SubSGD iter. 310/499: loss=77.74533800359428, w0=72.10000000000014, w1=15.479774607815633\n",
      "SubSGD iter. 311/499: loss=83.45444679740645, w0=71.40000000000013, w1=16.319802179275445\n",
      "SubSGD iter. 312/499: loss=84.31247183392429, w0=72.10000000000014, w1=16.76998192548174\n",
      "SubSGD iter. 313/499: loss=78.98987525113101, w0=72.80000000000014, w1=15.985749197442416\n",
      "SubSGD iter. 314/499: loss=82.35330392139358, w0=72.10000000000014, w1=16.417541775725837\n",
      "SubSGD iter. 315/499: loss=81.03471290397563, w0=72.80000000000014, w1=16.382850916384367\n",
      "SubSGD iter. 316/499: loss=78.45416461018056, w0=73.50000000000014, w1=16.0072650780978\n",
      "SubSGD iter. 317/499: loss=83.06018539917778, w0=74.20000000000014, w1=16.886513043993972\n",
      "SubSGD iter. 318/499: loss=85.3038861037114, w0=73.50000000000014, w1=17.233597029613964\n",
      "SubSGD iter. 319/499: loss=88.57897424166735, w0=72.80000000000014, w1=17.64467221415619\n",
      "SubSGD iter. 320/499: loss=84.50515907024251, w0=72.10000000000014, w1=16.80348204593155\n",
      "SubSGD iter. 321/499: loss=85.93024997786212, w0=72.80000000000014, w1=17.230999131148966\n",
      "SubSGD iter. 322/499: loss=82.17472542980985, w0=73.50000000000014, w1=16.706366206437227\n",
      "SubSGD iter. 323/499: loss=82.78075464490317, w0=72.80000000000014, w1=16.699938325558882\n",
      "SubSGD iter. 324/499: loss=77.43697495412125, w0=73.50000000000014, w1=15.798306061146125\n",
      "SubSGD iter. 325/499: loss=80.41058178366137, w0=74.20000000000014, w1=16.414693009983374\n",
      "SubSGD iter. 326/499: loss=80.69946274186266, w0=73.50000000000014, w1=16.439990775372216\n",
      "SubSGD iter. 327/499: loss=80.41774816146842, w0=74.20000000000014, w1=16.416024935569126\n",
      "SubSGD iter. 328/499: loss=81.58971350736275, w0=74.90000000000015, w1=16.56891869268371\n",
      "SubSGD iter. 329/499: loss=79.45320648491757, w0=74.20000000000014, w1=16.233690637380455\n",
      "SubSGD iter. 330/499: loss=82.62759356049004, w0=73.50000000000014, w1=16.785662069318136\n",
      "SubSGD iter. 331/499: loss=83.97031195489951, w0=72.80000000000014, w1=16.906166620797176\n",
      "SubSGD iter. 332/499: loss=84.07152702028084, w0=72.10000000000014, w1=16.727814499417363\n",
      "SubSGD iter. 333/499: loss=88.18002435670734, w0=72.80000000000014, w1=17.5840365519219\n",
      "SubSGD iter. 334/499: loss=95.13730587181573, w0=72.10000000000014, w1=18.420075409194716\n",
      "SubSGD iter. 335/499: loss=96.6081311544583, w0=72.80000000000014, w1=18.764543656065182\n",
      "SubSGD iter. 336/499: loss=91.70067063875278, w0=73.50000000000014, w1=18.19153357305056\n",
      "SubSGD iter. 337/499: loss=86.4372132041298, w0=72.80000000000014, w1=17.312285607154386\n",
      "SubSGD iter. 338/499: loss=91.30996698295431, w0=72.10000000000014, w1=17.88224573169037\n",
      "SubSGD iter. 339/499: loss=99.43148887782026, w0=72.80000000000014, w1=19.121562032668372\n",
      "SubSGD iter. 340/499: loss=94.89568986382469, w0=72.10000000000014, w1=18.387286289176572\n",
      "SubSGD iter. 341/499: loss=90.02609246986141, w0=72.80000000000014, w1=17.860097650429346\n",
      "SubSGD iter. 342/499: loss=81.8332148111973, w0=72.10000000000014, w1=16.320035312042158\n",
      "SubSGD iter. 343/499: loss=77.34566889133912, w0=72.80000000000014, w1=15.641688316067615\n",
      "SubSGD iter. 344/499: loss=71.94968181650643, w0=73.50000000000014, w1=14.457686115673724\n",
      "SubSGD iter. 345/499: loss=69.91291923054162, w0=74.20000000000014, w1=13.85392004570721\n",
      "SubSGD iter. 346/499: loss=68.66981368035357, w0=73.50000000000014, w1=13.305525541949399\n",
      "SubSGD iter. 347/499: loss=72.70164010068959, w0=72.80000000000014, w1=14.48952774234329\n",
      "SubSGD iter. 348/499: loss=74.36471993677168, w0=73.50000000000014, w1=15.10252023952685\n",
      "SubSGD iter. 349/499: loss=77.11892818210751, w0=72.80000000000014, w1=15.592203772923439\n",
      "SubSGD iter. 350/499: loss=80.87000716280794, w0=73.50000000000014, w1=16.47145173881961\n",
      "SubSGD iter. 351/499: loss=78.68146161870519, w0=72.80000000000014, w1=15.9230572350618\n",
      "SubSGD iter. 352/499: loss=84.28090856729185, w0=72.10000000000014, w1=16.764475744787745\n",
      "SubSGD iter. 353/499: loss=84.78067273655527, w0=72.80000000000014, w1=17.04260271358943\n",
      "SubSGD iter. 354/499: loss=86.8779129236969, w0=73.50000000000014, w1=17.482527156473612\n",
      "SubSGD iter. 355/499: loss=85.93797673257473, w0=72.80000000000014, w1=17.232246040011557\n",
      "SubSGD iter. 356/499: loss=89.48665305635033, w0=73.50000000000014, w1=17.87517573877535\n",
      "SubSGD iter. 357/499: loss=85.5788093247616, w0=74.20000000000014, w1=17.302165655760728\n",
      "SubSGD iter. 358/499: loss=87.55920144905737, w0=73.50000000000014, w1=17.587340150310023\n",
      "SubSGD iter. 359/499: loss=90.52299313917017, w0=72.80000000000014, w1=17.93251723803502\n",
      "SubSGD iter. 360/499: loss=91.29703522218203, w0=72.10000000000014, w1=17.88035689250531\n",
      "SubSGD iter. 361/499: loss=95.35568321074089, w0=71.40000000000013, w1=18.227440878125304\n",
      "SubSGD iter. 362/499: loss=90.76137957818602, w0=72.10000000000014, w1=17.801654730834564\n",
      "SubSGD iter. 363/499: loss=90.47326730153812, w0=71.40000000000013, w1=17.513157466277146\n",
      "SubSGD iter. 364/499: loss=93.08429170673608, w0=72.10000000000014, w1=18.136645588563322\n",
      "SubSGD iter. 365/499: loss=90.51812939593867, w0=72.80000000000014, w1=17.9318120686881\n",
      "SubSGD iter. 366/499: loss=94.72185357087803, w0=72.10000000000014, w1=18.36360464697152\n",
      "SubSGD iter. 367/499: loss=97.56833923211472, w0=72.80000000000014, w1=18.887785198423238\n",
      "SubSGD iter. 368/499: loss=98.48843586331449, w0=73.50000000000014, w1=19.08430528120174\n",
      "SubSGD iter. 369/499: loss=89.50638272664965, w0=74.20000000000014, w1=17.90030308080785\n",
      "SubSGD iter. 370/499: loss=84.94411439422018, w0=73.50000000000014, w1=17.175282890727043\n",
      "SubSGD iter. 371/499: loss=88.27499859347954, w0=72.80000000000014, w1=17.598522315499558\n",
      "SubSGD iter. 372/499: loss=95.63643465685114, w0=72.10000000000014, w1=18.487354139666053\n",
      "SubSGD iter. 373/499: loss=91.63137232504651, w0=72.80000000000014, w1=18.09137789644422\n",
      "SubSGD iter. 374/499: loss=92.50128139425719, w0=73.50000000000014, w1=18.302542291010425\n",
      "SubSGD iter. 375/499: loss=97.93636397209575, w0=74.20000000000014, w1=19.03450688451806\n",
      "SubSGD iter. 376/499: loss=93.23076342990937, w0=73.50000000000014, w1=18.40223245603637\n",
      "SubSGD iter. 377/499: loss=98.62713026438104, w0=74.20000000000014, w1=19.120395780067557\n",
      "SubSGD iter. 378/499: loss=88.68961239254881, w0=73.50000000000014, w1=17.75764438467581\n",
      "SubSGD iter. 379/499: loss=89.57670297663503, w0=74.20000000000014, w1=17.910538141790393\n",
      "SubSGD iter. 380/499: loss=82.31869995136097, w0=74.90000000000015, w1=16.699115253864214\n",
      "SubSGD iter. 381/499: loss=87.06615287566483, w0=74.20000000000014, w1=17.53515411113703\n",
      "SubSGD iter. 382/499: loss=85.3849252988025, w0=73.50000000000014, w1=17.24665684657961\n",
      "SubSGD iter. 383/499: loss=80.02326817275188, w0=72.80000000000014, w1=16.190255615200723\n",
      "SubSGD iter. 384/499: loss=76.4504389091138, w0=73.50000000000014, w1=15.586489545234208\n",
      "SubSGD iter. 385/499: loss=73.38258380782564, w0=72.80000000000014, w1=14.681314442047144\n",
      "SubSGD iter. 386/499: loss=78.0271393771262, w0=73.50000000000014, w1=15.920630743025145\n",
      "SubSGD iter. 387/499: loss=74.49156168169331, w0=72.80000000000014, w1=14.973718481282715\n",
      "SubSGD iter. 388/499: loss=72.47474935830769, w0=73.50000000000014, w1=14.607797750552317\n",
      "SubSGD iter. 389/499: loss=76.93337273562823, w0=72.80000000000014, w1=15.551304234089438\n",
      "SubSGD iter. 390/499: loss=74.1975179598307, w0=72.10000000000014, w1=14.59316914318763\n",
      "SubSGD iter. 391/499: loss=74.40259970872381, w0=71.40000000000013, w1=14.169627890133615\n",
      "SubSGD iter. 392/499: loss=75.52040227612453, w0=70.70000000000013, w1=13.83439983483036\n",
      "SubSGD iter. 393/499: loss=79.39729305257396, w0=70.00000000000013, w1=14.257639259602875\n",
      "SubSGD iter. 394/499: loss=80.91299264664686, w0=70.70000000000013, w1=15.35026377392867\n",
      "SubSGD iter. 395/499: loss=79.03828919134705, w0=70.00000000000013, w1=14.144247484158223\n",
      "SubSGD iter. 396/499: loss=83.98176711930266, w0=69.30000000000013, w1=14.691409786392093\n",
      "SubSGD iter. 397/499: loss=77.19348986293025, w0=70.00000000000013, w1=13.479986898465913\n",
      "SubSGD iter. 398/499: loss=74.97655332230049, w0=70.70000000000013, w1=13.632880655580495\n",
      "SubSGD iter. 399/499: loss=77.43431122741708, w0=70.00000000000013, w1=13.57657104053519\n",
      "SubSGD iter. 400/499: loss=77.45314922817138, w0=70.70000000000013, w1=14.455819006431362\n",
      "SubSGD iter. 401/499: loss=79.31667557443035, w0=71.40000000000013, w1=15.468257344297783\n",
      "SubSGD iter. 402/499: loss=75.27445276718736, w0=72.10000000000014, w1=14.883944806751892\n",
      "SubSGD iter. 403/499: loss=76.39635176217533, w0=71.40000000000013, w1=14.751621280398053\n",
      "SubSGD iter. 404/499: loss=70.6581999471526, w0=72.10000000000014, w1=13.397664386364825\n",
      "SubSGD iter. 405/499: loss=67.39719547952244, w0=72.80000000000014, w1=12.186241498438646\n",
      "SubSGD iter. 406/499: loss=69.44063406445876, w0=72.10000000000014, w1=12.809027905258938\n",
      "SubSGD iter. 407/499: loss=73.59036611553073, w0=71.40000000000013, w1=13.898822928332159\n",
      "SubSGD iter. 408/499: loss=70.00839668726353, w0=72.10000000000014, w1=13.104453583841378\n",
      "SubSGD iter. 409/499: loss=67.58406281912276, w0=72.80000000000014, w1=9.7313099062517\n",
      "SubSGD iter. 410/499: loss=68.47498302871223, w0=72.10000000000014, w1=9.932059443300952\n",
      "SubSGD iter. 411/499: loss=70.94836365546921, w0=71.40000000000013, w1=9.326656291856967\n",
      "SubSGD iter. 412/499: loss=71.97747675286966, w0=70.70000000000013, w1=10.168074801582911\n",
      "SubSGD iter. 413/499: loss=69.67938427955873, w0=71.40000000000013, w1=10.418355918044968\n",
      "SubSGD iter. 414/499: loss=73.6021980470119, w0=72.10000000000014, w1=7.648056221155979\n",
      "SubSGD iter. 415/499: loss=71.67213052796409, w0=72.80000000000014, w1=7.8923689448651135\n",
      "SubSGD iter. 416/499: loss=69.24261312520407, w0=73.50000000000014, w1=8.524643373346803\n",
      "SubSGD iter. 417/499: loss=67.73609944226627, w0=74.20000000000014, w1=9.13930435447719\n",
      "SubSGD iter. 418/499: loss=68.87099986836796, w0=74.90000000000015, w1=8.757178369926855\n",
      "SubSGD iter. 419/499: loss=83.07064990278526, w0=75.60000000000015, w1=5.384034692337178\n",
      "SubSGD iter. 420/499: loss=81.54363769914985, w0=76.30000000000015, w1=5.912090507847826\n",
      "SubSGD iter. 421/499: loss=81.59566493270283, w0=75.60000000000015, w1=5.651378286465962\n",
      "SubSGD iter. 422/499: loss=76.6959688875636, w0=74.90000000000015, w1=6.47003665627159\n",
      "SubSGD iter. 423/499: loss=74.50307032348523, w0=75.60000000000015, w1=7.1881999803027785\n",
      "SubSGD iter. 424/499: loss=72.10778253470374, w0=74.90000000000015, w1=7.6199925585861985\n",
      "SubSGD iter. 425/499: loss=70.16305168623673, w0=74.20000000000014, w1=8.128493676326032\n",
      "SubSGD iter. 426/499: loss=72.49172806361803, w0=74.90000000000015, w1=7.50935252091165\n",
      "SubSGD iter. 427/499: loss=71.783158362754, w0=75.60000000000015, w1=7.975934646878224\n",
      "SubSGD iter. 428/499: loss=69.73184788908773, w0=74.90000000000015, w1=8.406266235338961\n",
      "SubSGD iter. 429/499: loss=68.33519740414745, w0=74.20000000000014, w1=8.845954640424146\n",
      "SubSGD iter. 430/499: loss=67.46710875850728, w0=74.90000000000015, w1=9.492101873811368\n",
      "SubSGD iter. 431/499: loss=67.13951040535558, w0=74.20000000000014, w1=9.485673992933021\n",
      "SubSGD iter. 432/499: loss=66.22285370983832, w0=73.50000000000014, w1=10.523188186746562\n",
      "SubSGD iter. 433/499: loss=66.94178339835624, w0=72.80000000000014, w1=10.390864660392724\n",
      "SubSGD iter. 434/499: loss=66.48355330353161, w0=73.50000000000014, w1=10.149884745726077\n",
      "SubSGD iter. 435/499: loss=66.7355950377954, w0=72.80000000000014, w1=10.985923602998893\n",
      "SubSGD iter. 436/499: loss=66.11205748367675, w0=73.50000000000014, w1=11.235522065686071\n",
      "SubSGD iter. 437/499: loss=66.93437333328637, w0=72.80000000000014, w1=11.667314643969492\n",
      "SubSGD iter. 438/499: loss=66.48090993548279, w0=73.50000000000014, w1=11.91691310665667\n",
      "SubSGD iter. 439/499: loss=67.39967525102416, w0=72.80000000000014, w1=12.188393288639249\n",
      "SubSGD iter. 440/499: loss=66.86324606006895, w0=73.50000000000014, w1=12.276920802128375\n",
      "SubSGD iter. 441/499: loss=66.33737825262746, w0=74.20000000000014, w1=11.926982870648057\n",
      "SubSGD iter. 442/499: loss=67.23935408832493, w0=73.50000000000014, w1=12.54976927746835\n",
      "SubSGD iter. 443/499: loss=67.73197640520246, w0=74.20000000000014, w1=12.928309060825082\n",
      "SubSGD iter. 444/499: loss=71.08023831460474, w0=74.90000000000015, w1=14.13432535059553\n",
      "SubSGD iter. 445/499: loss=69.51965933836836, w0=74.20000000000014, w1=13.710784097541515\n",
      "SubSGD iter. 446/499: loss=69.76555406162278, w0=73.50000000000014, w1=13.745474956882985\n",
      "SubSGD iter. 447/499: loss=71.55806638372988, w0=72.80000000000014, w1=14.14091174882599\n",
      "SubSGD iter. 448/499: loss=75.49468284716447, w0=72.10000000000014, w1=14.9407424828887\n",
      "SubSGD iter. 449/499: loss=81.56336356604184, w0=72.80000000000014, w1=16.480804821275886\n",
      "SubSGD iter. 450/499: loss=87.632109657424, w0=72.10000000000014, w1=17.32222333100183\n",
      "SubSGD iter. 451/499: loss=84.92628414499552, w0=72.80000000000014, w1=17.066791449900258\n",
      "SubSGD iter. 452/499: loss=82.14357303146134, w0=73.50000000000014, w1=16.70087071916986\n",
      "SubSGD iter. 453/499: loss=76.93366466131388, w0=74.20000000000014, w1=15.724073240227941\n",
      "SubSGD iter. 454/499: loss=75.4843638447694, w0=73.50000000000014, w1=15.369045762698116\n",
      "SubSGD iter. 455/499: loss=75.9633879831722, w0=74.20000000000014, w1=15.512376353292632\n",
      "SubSGD iter. 456/499: loss=67.73423848291242, w0=74.90000000000015, w1=12.742076656403643\n",
      "SubSGD iter. 457/499: loss=69.21890011280372, w0=74.20000000000014, w1=13.595922926828912\n",
      "SubSGD iter. 458/499: loss=70.21197210887776, w0=74.90000000000015, w1=13.840235650538046\n",
      "SubSGD iter. 459/499: loss=71.57524040808444, w0=74.20000000000014, w1=14.392207082475725\n",
      "SubSGD iter. 460/499: loss=70.66175902342698, w0=74.90000000000015, w1=13.996230839253892\n",
      "SubSGD iter. 461/499: loss=73.14949555039952, w0=74.20000000000014, w1=14.832269696526708\n",
      "SubSGD iter. 462/499: loss=72.2194142366418, w0=74.90000000000015, w1=14.482331765046391\n",
      "SubSGD iter. 463/499: loss=73.8714393151838, w0=74.20000000000014, w1=15.017851447872596\n",
      "SubSGD iter. 464/499: loss=78.09752018237555, w0=74.90000000000015, w1=15.897099413768768\n",
      "SubSGD iter. 465/499: loss=76.96754618936038, w0=74.20000000000014, w1=15.731293154201271\n",
      "SubSGD iter. 466/499: loss=76.46028356627541, w0=74.90000000000015, w1=15.547827375150852\n",
      "SubSGD iter. 467/499: loss=77.38477014819074, w0=74.20000000000014, w1=15.819307557133431\n",
      "SubSGD iter. 468/499: loss=75.7560147745241, w0=74.90000000000015, w1=15.388975968672694\n",
      "SubSGD iter. 469/499: loss=77.42958079540614, w0=74.20000000000014, w1=15.82866437375788\n",
      "SubSGD iter. 470/499: loss=80.3547081465967, w0=73.50000000000014, w1=16.37582667599175\n",
      "SubSGD iter. 471/499: loss=83.13923925484167, w0=74.20000000000014, w1=16.900007227443467\n",
      "SubSGD iter. 472/499: loss=80.53736395728636, w0=74.90000000000015, w1=16.37537430273173\n",
      "SubSGD iter. 473/499: loss=82.4337213912912, w0=75.60000000000015, w1=16.57189438551023\n",
      "SubSGD iter. 474/499: loss=84.94276964486214, w0=76.30000000000015, w1=16.783058780076434\n",
      "SubSGD iter. 475/499: loss=83.1202816451907, w0=75.60000000000015, w1=16.69453126658731\n",
      "SubSGD iter. 476/499: loss=91.43860273809085, w0=76.30000000000015, w1=17.819661226717614\n",
      "SubSGD iter. 477/499: loss=89.52256938166487, w0=77.00000000000016, w1=17.24665114370299\n",
      "SubSGD iter. 478/499: loss=86.19166850236554, w0=76.30000000000015, w1=16.996370027240935\n",
      "SubSGD iter. 479/499: loss=83.70104594142309, w0=77.00000000000016, w1=16.225546961172746\n",
      "SubSGD iter. 480/499: loss=81.99012214527875, w0=76.30000000000015, w1=16.244126420071623\n",
      "SubSGD iter. 481/499: loss=87.35350701946379, w0=77.00000000000016, w1=16.887056118835417\n",
      "SubSGD iter. 482/499: loss=81.6896465717017, w0=76.30000000000015, w1=16.186122121400665\n",
      "SubSGD iter. 483/499: loss=77.79139663306033, w0=75.60000000000015, w1=15.658066305890015\n",
      "SubSGD iter. 484/499: loss=82.13078184126623, w0=76.30000000000015, w1=16.271058803073576\n",
      "SubSGD iter. 485/499: loss=79.95880304068025, w0=75.60000000000015, w1=16.10525254350608\n",
      "SubSGD iter. 486/499: loss=73.8899105245642, w0=74.90000000000015, w1=14.936921742988611\n",
      "SubSGD iter. 487/499: loss=71.23762425947973, w0=75.60000000000015, w1=13.909989545396078\n",
      "SubSGD iter. 488/499: loss=70.81662282932683, w0=76.30000000000015, w1=13.223294909889942\n",
      "SubSGD iter. 489/499: loss=67.7435374220804, w0=75.60000000000015, w1=12.165379603062384\n",
      "SubSGD iter. 490/499: loss=67.05872440924809, w0=74.90000000000015, w1=12.285271416550716\n",
      "SubSGD iter. 491/499: loss=67.24567619935524, w0=74.20000000000014, w1=12.651192147281114\n",
      "SubSGD iter. 492/499: loss=66.87008246778379, w0=74.90000000000015, w1=12.124003508533887\n",
      "SubSGD iter. 493/499: loss=67.40476007861959, w0=74.20000000000014, w1=12.74678991535418\n",
      "SubSGD iter. 494/499: loss=69.26322862718187, w0=74.90000000000015, w1=13.478754508861815\n",
      "SubSGD iter. 495/499: loss=67.8372744047557, w0=74.20000000000014, w1=12.983128248392983\n",
      "SubSGD iter. 496/499: loss=68.03934444270165, w0=73.50000000000014, w1=13.008426013781826\n",
      "SubSGD iter. 497/499: loss=69.92347758560844, w0=72.80000000000014, w1=13.560397445719504\n",
      "SubSGD iter. 498/499: loss=71.36753691314996, w0=72.10000000000014, w1=13.680901997198546\n",
      "SubSGD iter. 499/499: loss=74.2516467258108, w0=71.40000000000013, w1=14.121097251905518\n",
      "SubSGD: execution time=0.012 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562be528f79448dd8af69b221380c8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
